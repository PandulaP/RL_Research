{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import pandas as pd\n",
    "import _set_path\n",
    "from pbpi.algo_core.training import evaluations_per_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALGO_TYPE = {'original': {'name': 'original', 'exploration': False}\n",
    "            ,'modified': {'name': 'modified', 'exploration': True} }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "################## INPUTS ##################\n",
    "\n",
    "# Configs to test\n",
    "N_STATES = 40\n",
    "\n",
    "configs = { 'CONFIG_NO': 1\n",
    "          , 'S': [N_STATES]\n",
    "          , 'Actions' : [3]\n",
    "          , 'Roll-outs': [10, 20, 50, 100]\n",
    "          , 'Significance' : [0.1, 0.05, 0.025]\n",
    "          , 'init_state_path': './manual_init_state_input/uniformly_sampled_states.csv'\n",
    "          }\n",
    "\n",
    "algorithm = ALGO_TYPE['modified']\n",
    "\n",
    "############################################\n",
    "############################################\n",
    "\n",
    "# Algorithm configs\n",
    "ALGO_NAME = algorithm['name']\n",
    "EXPLORE_LOGIC = algorithm['exploration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment execution\n",
    "agg_results = []\n",
    "\n",
    "eval_count = len(configs['S'])*len(configs['Actions'])*len(configs['Roll-outs'])*len(configs['Significance'])\n",
    "\n",
    "pbar_evals = tqdm.tqdm(total=eval_count, desc=\"Evaluations\")\n",
    "\n",
    "for sample_size in configs['S']:\n",
    "        \n",
    "    for rollout_max in configs['Roll-outs']:\n",
    "\n",
    "        for sig_lvl in configs['Significance']:\n",
    "\n",
    "            run_results = evaluations_per_config(s_size          = sample_size\n",
    "                                                , n_actions      = configs['Actions'][0]\n",
    "                                                , max_n_rollouts = rollout_max\n",
    "                                                , sig_lvl        = sig_lvl\n",
    "\n",
    "                                                , max_policy_iter_per_run = 10\n",
    "                                                , runs_per_config         = 10\n",
    "                                                \n",
    "                                                , off_policy_explr = EXPLORE_LOGIC\n",
    "\n",
    "                                                , rollout_tracking          = False\n",
    "                                                , dataset_tracking          = False\n",
    "                                                , train_plot_tracking       = False\n",
    "                                                , eval_summary_tracking     = False \n",
    "                                                , show_experiment_eval_plot = False\n",
    "                                                \n",
    "                                                , init_state_path       = configs['init_state_path']\n",
    "                                                )\n",
    "\n",
    "            agg_results.append(run_results)\n",
    "\n",
    "            pbar_evals.update(1)\n",
    "                \n",
    "pbar_evals.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the evaluation results\n",
    "results_dfs = []\n",
    "for result in agg_results:\n",
    "    results_dfs.append(pd.DataFrame(result))\n",
    "\n",
    "results_df = pd.concat(results_dfs)\n",
    "\n",
    "results_df.to_excel(f\"eval_results/{ALGO_NAME}_experiment_results_para_config_{configs['CONFIG_NO']}.xlsx\", index=False)"
   ]
  }
 ]
}