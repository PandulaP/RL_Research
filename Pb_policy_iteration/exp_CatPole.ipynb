{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preference-based Policy Iteration Algorithm\n",
    "\n",
    "This is an attempt to replicate the work done by FÃ¼rnkranz et al., (2012) in their paper \"Preference-based reinforcement learning: a formal framework and a policy iteration algorithm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "from IPython.display import HTML\n",
    "import gym\n",
    "from gym import wrappers\n",
    "import io\n",
    "import base64\n",
    "import itertools\n",
    "import tqdm\n",
    "\n",
    "from scipy.stats import rankdata as rd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**State observation**:\n",
    "    \n",
    "    Type: Box(4)\n",
    "\n",
    "    Num     Observation               Min                     Max\n",
    "    0       Cart Position             -4.8                    4.8\n",
    "    1       Cart Velocity             -Inf                    Inf\n",
    "    2       Pole Angle                -0.418 rad (-24 deg)    0.418 rad (24 deg)\n",
    "    3       Pole Angular Velocity     -Inf                    Inf\n",
    "\n",
    "- For this project, I will describe the state of the pendulum using only the angle and angular velocity of the pole, ignoring the position and the velocity of cart.\n",
    "\n",
    "**Actions**:\n",
    "\n",
    "    Type: Discrete(2)\n",
    "    \n",
    "    Num   Action\n",
    "    0     Push cart to the left\n",
    "    1     Push cart to the right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of actions: 2\n",
      "Observation space: Box(4,)\n",
      "Max. values of observation space:[4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38]\n",
      "Min. values of observation space:[-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38]\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('CartPole-v0')\n",
    "env.reset()\n",
    "\n",
    "print(\"Number of actions: \" + str(env.action_space.n))\n",
    "print(\"Observation space: \" + str(env.observation_space))\n",
    "print(\"Max. values of observation space:\" + str(env.observation_space.high))\n",
    "print(\"Min. values of observation space:\" + str(env.observation_space.low))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def state_filter(state):\n",
    "    \"\"\" only use the angle and the angular velocity of the pole to describe the state\"\"\"\n",
    "    \n",
    "    return state[[2,3]]\n",
    "\n",
    "\n",
    "def random_action(state):\n",
    "    \"\"\" return a random action: either 0 (left) or 1 (right)\"\"\"\n",
    "    \n",
    "    action = env.action_space.sample()  \n",
    "    return action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I generate random samples $S$ in this setting by simulating a uniform random number (max 100) of uniform random actions from the initial state. If the pendulum fell within this sequence, the procedure was repeated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_init_states_S(seed, filter_state=True):\n",
    "    \"\"\"this function returns a list of randomly generated initial states from the CartPole-v0 environment \"\"\"\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    n_actions = np.random.randint(low=1, high=101)                # how many actions to generate\n",
    "    seq_actions = np.random.randint(low=0,high=2,size=n_actions)  # random sequence of actions\n",
    "\n",
    "    init_states_S = []   # to store initial states\n",
    "\n",
    "    env = gym.make('CartPole-v0')\n",
    "    env.reset()\n",
    "\n",
    "    for action in seq_actions:\n",
    "\n",
    "        state, reward, done, info = env.step(action)  # implement the actions in the random sequence\n",
    "        \n",
    "        if filter_state:\n",
    "            init_states_S.append(state_filter(state)) # append the environment state to list (only angular velocity and angle)\n",
    "        else:\n",
    "            init_states_S.append(state) # all 4 state observations\n",
    "            \n",
    "        if done: # the episode ends either if the pole is > 15 deg from vertical or the cart move by > 2.4 unit from the centre\n",
    "            env.reset()    \n",
    "            \n",
    "    env.close()\n",
    "            \n",
    "    return init_states_S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Generate a sequence of intial states (for $S$) and display first 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "init_states_S = generate_init_states_S(16) # randomly generated states initial\n",
    "\n",
    "env = gym.make('CartPole-v0') # create inv. pend environment\n",
    "env = env.unwrapped           # unwrap the environment to send custom initial states\n",
    "fig = plt.figure(figsize=(20,5))\n",
    "\n",
    "for i in range(10):\n",
    "    env.state = np.concatenate((np.array([0.0,0.0]),init_states_S[i])) # manually adding cart-posi & cart-velocity\n",
    "    fig.add_subplot(2,5,i+1)\n",
    "    plt.imshow(env.render(mode=\"rgb_array\"))\n",
    "    env.close()\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I partition the action space to create multiple actions, because in these cases it becomes less and less likely that a unique best actions can be found. The range of the original action set {0, 1} is partitioned equidistantly into the given number of actions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_action_space(env,n_actions):\n",
    "    \"\"\"this function partitions the action space of a given environment into a given number of `n_actions`\"\"\"\n",
    "    \n",
    "    actions = np.arange(env.action_space.n)\n",
    "\n",
    "    # a uniform noise term is added to action signals to make all state transitions non-deterministic\n",
    "    part_act_space = np.linspace(actions[0],actions[-1],n_actions) + np.random.uniform(low = -.2,high=.2) \n",
    "    \n",
    "    return part_act_space                                                                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original action space: 2\n",
      "Partitioned into 3 actions: [-0.12215384  0.37784616  0.87784616]\n",
      "Partitioned into 9 actions: [-0.09014737  0.03485263  0.15985263  0.28485263  0.40985263  0.53485263\n",
      "  0.65985263  0.78485263  0.90985263]\n",
      "Partitioned into 17 actions: [-0.14760155 -0.08510155 -0.02260155  0.03989845  0.10239845  0.16489845\n",
      "  0.22739845  0.28989845  0.35239845  0.41489845  0.47739845  0.53989845\n",
      "  0.60239845  0.66489845  0.72739845  0.78989845  0.85239845]\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('CartPole-v0')\n",
    "\n",
    "print(\"Original action space: \" + str(env.action_space.n))\n",
    "print(\"Partitioned into 3 actions: \" + str(partition_action_space(env,3)))\n",
    "print(\"Partitioned into 9 actions: \" + str(partition_action_space(env,9)))\n",
    "print(\"Partitioned into 17 actions: \" + str(partition_action_space(env,17)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preference-based Approximate Policy Iteration algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "### Evaluate-Preference procedure ###\n",
    "\n",
    "### Description:\n",
    "###  This is done using roll-outs\n",
    "###  At every state in the initial state set, roll-outs are generated from each action for the same policy\n",
    "###  Accumulated rewards from each roll-out from each action are used to generate preferences for every pair of actions\n",
    "###  Generated preferences are stored in the training set; training data are used to learn the LabelRanker\n",
    "\n",
    "### Functionality:\n",
    "### - INPUTS  : starting state (s), two-actions(a_k, a_j), (current) policy (\\pi), max. length of trajectoris (L)\n",
    "### - PROCESS : generate roll-out (fixed time horizon) and calculate accumulate reward\n",
    "### - OUTPUT  : compare return from each rollout: store preference info in training dataset as (s,a_k > a_j)\n",
    "\n",
    "### - Run this procedure for every action-pair at all initial-states\n",
    "\n",
    "def evaluate_preference(starting_state\n",
    "                        , action_1\n",
    "                        , action_2\n",
    "                        , policy\n",
    "                        , environment_name = 'CartPole-v0'\n",
    "                        , discount_fac = 1\n",
    "                        , n_rollouts = 15\n",
    "                        , max_rollout_len = 1500\n",
    "                       ):\n",
    "    \n",
    "    policy = policy              # policy to follow in roll-outs\n",
    "    n_rollouts = n_rollouts      # number of roll-outs to generate\n",
    "    gamma = discount_fac         # discount factor\n",
    "\n",
    "    # state is 4 dimensional by default: if only 2 give, has to expand to 4 dimensions\n",
    "    if len(starting_state) == 2:\n",
    "        # manually define state-values for 'cart-position' & 'cart-velocity'\n",
    "        cart_posi, cart_velo = 0,0   \n",
    "        s_init = np.concatenate((np.array([cart_posi,cart_velo]),starting_state))\n",
    "    else:\n",
    "        s_init = starting_state\n",
    "        \n",
    "    # dict. to store actions\n",
    "    actions = { 'one' : action_1 \n",
    "              , 'two' : action_2}    \n",
    "\n",
    "    # dict to store  rewards of roll-outs starting from each action\n",
    "    r = { 'one' : [None]*n_rollouts \n",
    "        , 'two' : [None]*n_rollouts}  \n",
    "\n",
    "    # dict to store average discounted return for for each action\n",
    "    avg_r = {}  \n",
    "\n",
    "    max_traj_len = max_rollout_len # maximum roll-out trajectory length\n",
    "\n",
    "    for action_key, action_value in actions.items():\n",
    "\n",
    "        # generate roll-outs\n",
    "        for rollout in range(n_rollouts):\n",
    "\n",
    "            env = gym.make(environment_name)\n",
    "            env = env.unwrapped\n",
    "\n",
    "            env.state = s_init  # set the starting state\n",
    "\n",
    "            # absolute of the rounded action value is applied in case action space is partitioned\n",
    "            #print(abs(round(action_value)))\n",
    "            observation, reward, done, info = env.step(int(abs(round(action_value))))\n",
    "\n",
    "            r[action_key][rollout] = reward # add the immediate reward of the action\n",
    "\n",
    "            traj_len = 1\n",
    "            while traj_len < max_traj_len and not done:\n",
    "\n",
    "                observation, reward, done, info = env.step(policy(observation)) ### NEED TO DEFINE A POLICY\n",
    "\n",
    "                r[action_key][rollout] += (gamma**traj_len) * reward\n",
    "\n",
    "                traj_len += 1\n",
    "\n",
    "            env.reset()\n",
    "            env.close()\n",
    "\n",
    "        # calculate average discounted return \n",
    "        avg_r[action_key]  = sum(r[action_key]) / len(r[action_key])\n",
    "\n",
    "    ### TO-DO ###\n",
    "    # RUN T-TEST AND RETURN ACTION PREFERENCE ONLY IF THERE IS A SIGNIFICANT DIFFERENCE\n",
    "    \n",
    "    # return preference info. to generate training data\n",
    "    if avg_r['one'] > avg_r['two']:\n",
    "        return {'state': s_init[[2,3]] if len(s_init)>2 else s_init # only use the angel and velocity of pendulum for state\n",
    "               , 'a_j' : actions['one']\n",
    "               , 'a_k' : actions['two']\n",
    "               , 'preference_label' : 1}\n",
    "#     elif avg_r['two'] > avg_r['one']:\n",
    "#         return {'state': s_init[[2,3]] if len(s_init)>2 else s_init  # only use the angel and velocity of pendulum for state\n",
    "#                , 'a_k_prefered_a_j' : [actions['two'],actions['one']]\n",
    "#                , 'preference_label' : 1}\n",
    "    else:\n",
    "        return {'state': s_init[[2,3]] if len(s_init)>2 else s_init # only use the angel and velocity of pendulum for state\n",
    "               , 'a_j' : actions['one']\n",
    "               , 'a_k' : actions['two']\n",
    "               , 'preference_label' : 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': array([0.04932088, 0.04057652]),\n",
       " 'a_j': 0.3,\n",
       " 'a_k': 0.6,\n",
       " 'preference_label': 0}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_preference(env.reset(),0.3,0.6,random_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "### LABEL-RANKER MODEL-TRAINING procedure ###\n",
    "\n",
    "### Description:\n",
    "###  XXX..\n",
    "\n",
    "### Functionality:\n",
    "### - INPUTS  :\n",
    "### - PROCESS : \n",
    "### - OUTPUT  : \n",
    "\n",
    "### FUNCTION TO CREATE TRAINING DATASET + MODEL + RETURN THE TRAINED MODEL ###\n",
    "\n",
    "def train_model(train_data, batch_s = 3, mod_layers = [100,500,50], n_epochs = 300):\n",
    "\n",
    "    ###########################################\n",
    "    ###### CONSTRUCTING TRAINING-DATASET ######\n",
    "\n",
    "    # create a training dataframe\n",
    "    train_df = pd.DataFrame(train_data)\n",
    "\n",
    "    # create a key for each state\n",
    "    train_df.loc[:, 'state_key'] = train_df.state.apply(lambda x: x[0].astype(str)+\"_\"+x[1].astype(str))\n",
    "\n",
    "    # drop all states (rows) which does not include any preferred action\n",
    "    temp_df1 = train_df.groupby('state_key').preference_label.sum().reset_index()\n",
    "    temp_df1 = temp_df1.loc[temp_df1.preference_label>0] # pick the states that have at least one prefered action\n",
    "    train_df = train_df.merge(right = temp_df1.loc[:,'state_key']\n",
    "                              , right_on = 'state_key'\n",
    "                              , left_on = 'state_key'\n",
    "                              , how = 'right')\n",
    "\n",
    "    ## create a single column to include the set of all actions executed at each state\n",
    "    temp_df1 = train_df.groupby('state_key')['a_j'].unique().reset_index()\n",
    "    temp_df2 = train_df.groupby('state_key')['a_k'].unique().reset_index()\n",
    "    temp_df3 = temp_df1.merge(right=temp_df2\n",
    "                              , right_on = 'state_key'\n",
    "                              , left_on = 'state_key'\n",
    "                              , how = 'inner')\n",
    "    temp_df3.loc[:,'unique_acts'] = temp_df3.apply(lambda row: set(list(row['a_j']) + list(row['a_k'])) ,axis=1)\n",
    "\n",
    "    # add the unique-action column to train dataset\n",
    "    train_df = train_df.merge(right = temp_df3.loc[:,['state_key', 'unique_acts']]\n",
    "                  , right_on =  'state_key'\n",
    "                  , left_on = 'state_key'\n",
    "                  , how = 'left')\n",
    "\n",
    "    # create a 'prefered-action' value for each state, action-preference pair\n",
    "    train_df.loc[:,'prefered_action'] = train_df.apply(lambda row: row['a_j'] if row['preference_label'] == 1 else row['a_k']  ,axis=1)\n",
    "\n",
    "    # count the number of times each action is prefered at a state\n",
    "    action_preference_counts = train_df.groupby('state_key').prefered_action.value_counts().unstack()\n",
    "    action_preference_counts.replace(np.nan,0,inplace=True) # if an action is not preferred every, set it to '0'\n",
    "\n",
    "    # convert the action-preference-counts to a vector and add as a new column (to be used as training labels)\n",
    "    action_preference_counts.loc[:, 'preference_label_vector'] = action_preference_counts.iloc[:,0:].values.tolist()\n",
    "\n",
    "    # add preference label vector to training dataset\n",
    "    train_df = train_df.merge(right = action_preference_counts.loc[:,['preference_label_vector']]\n",
    "                              , right_index= True\n",
    "                              , left_on = 'state_key'\n",
    "                              , how = 'left')\n",
    "\n",
    "    # create the reduced training dataset (drop unnecessary columns + duplicate rows: which have data for same state)\n",
    "    train_df_reduced = train_df.loc[:,['state', 'state_key', 'unique_acts', 'preference_label_vector']]\n",
    "    train_df_reduced.drop_duplicates(subset=['state_key'],inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "    ###### PREPARING TRAINING-DATA TENSORS (FOR MODEL) ######\n",
    "\n",
    "    # normalizing the target (preference label) vectors\n",
    "    output_labels_temp = np.array(train_df_reduced.preference_label_vector.tolist())\n",
    "    row_sums = output_labels_temp.sum(axis=1)\n",
    "    output_labels_normalized = output_labels_temp / row_sums[:, np.newaxis]\n",
    "\n",
    "    # creating training data tensors\n",
    "    input_states  = torch.from_numpy(np.array(train_df_reduced.state.apply(lambda x: x.astype(float)).tolist()))\n",
    "    output_labels = torch.from_numpy(output_labels_normalized)\n",
    "\n",
    "    # create TensorDataset\n",
    "    train_ds = TensorDataset(input_states , output_labels)\n",
    "\n",
    "    # define data loader\n",
    "    batch_size = batch_s\n",
    "    train_dl = DataLoader(train_ds, batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "\n",
    "    ###### CREATING NEURAL NETWORK FUNCTION APPROXIMATOR (MODEL) ######\n",
    "\n",
    "    class Model(nn.Module):\n",
    "\n",
    "        def __init__(self, input_state_len, output_label_len, layers, p=0.4):\n",
    "\n",
    "            super().__init__()\n",
    "            self.batch_norm_num = nn.BatchNorm1d(input_state_len)\n",
    "\n",
    "            all_layers = []\n",
    "            input_size = input_state_len\n",
    "\n",
    "            # create layers\n",
    "            for layer_dim in layers:\n",
    "                all_layers.append(nn.Linear(input_size, layer_dim))\n",
    "                all_layers.append(nn.ReLU(inplace=True))\n",
    "                all_layers.append(nn.BatchNorm1d(layer_dim))\n",
    "                all_layers.append(nn.Dropout(p))\n",
    "                input_size = layer_dim\n",
    "\n",
    "            all_layers.append(nn.Linear(layers[-1], output_label_len))\n",
    "\n",
    "            self.layers = nn.Sequential(*all_layers)\n",
    "\n",
    "        def forward(self, state_vec):\n",
    "            x = self.batch_norm_num(state_vec)\n",
    "            x = self.layers(x)\n",
    "            return x\n",
    "\n",
    "    # define model instance\n",
    "    model = Model(input_states.shape[1], output_labels.shape[1], mod_layers, p=0.4)\n",
    "\n",
    "    opt = torch.optim.SGD(model.parameters(), lr = 1e-1)\n",
    "    loss_fn = F.mse_loss\n",
    "\n",
    "\n",
    "    ###### DEFINING FIT-FUNCTION TO TRAIN THE MODEL ######\n",
    "\n",
    "    print('Training model...\\n',end='\\r')\n",
    "\n",
    "    # to store losses\n",
    "    aggregated_losses = []\n",
    "\n",
    "    # Define a utility function to train the model\n",
    "    def fit(num_epochs, model, loss_fn, opt):\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            for xb,yb in train_dl:\n",
    "\n",
    "                # Generate predictions\n",
    "                pred = model(xb.float())\n",
    "                loss = loss_fn(pred, yb.float())            \n",
    "\n",
    "                # Perform gradient descent\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "                opt.zero_grad()\n",
    "\n",
    "            aggregated_losses.append(loss_fn(model(input_states.float()), output_labels.float()).detach().numpy())\n",
    "\n",
    "            if epoch%25 == 0:\n",
    "                    print(f'epoch: {epoch:3} loss: {loss.item():10.8f}')\n",
    "\n",
    "        print('\\nTraining loss: ', loss_fn(model(input_states.float()), output_labels.float()).detach().numpy(),'\\n', end = '\\r')\n",
    "\n",
    "\n",
    "    ###### TRAINING-DATA THE MODEL ######\n",
    "\n",
    "    epochs = n_epochs\n",
    "    fit(epochs, model, loss_fn, opt)\n",
    "\n",
    "    # plotting model loss\n",
    "    plt.plot(range(epochs), aggregated_losses)\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.show()\n",
    "\n",
    "    # set the model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    #return the model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "epoch:   0 loss: 6.15239525\n",
      "epoch:  25 loss: 0.10474766\n",
      "epoch:  50 loss: 0.02695465\n",
      "epoch:  75 loss: 0.04361059\n",
      "epoch: 100 loss: 0.04010206\n",
      "epoch: 125 loss: 0.05314644\n",
      "epoch: 150 loss: 0.04990267\n",
      "epoch: 175 loss: 0.05205442\n",
      "epoch: 200 loss: 0.03147303\n",
      "epoch: 225 loss: 0.10924534\n",
      "epoch: 250 loss: 0.05779817\n",
      "epoch: 275 loss: 0.07141671\n",
      "\n",
      "Training loss:  0.033435386 \n",
      "\r"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-Prediction: tensor([0.3902, 0.3952, 0.2106])\n",
      "-Target: tensor([0.3333, 0.6667, 0.0000], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "model = train_model(train_data)\n",
    "\n",
    "# making a sample prediction\n",
    "with torch.no_grad():\n",
    "    preds = model(input_states.float())\n",
    "    \n",
    "a = np.random.randint(10)\n",
    "print(f' - Prediction: {preds[a]}\\n - Target: {output_labels[a]}')\n",
    "# No need to worry about absolute values: only interested in the rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ| 1/1 [00:01<00:00,  1.56s/it]\n"
     ]
    }
   ],
   "source": [
    "###################################################\n",
    "### Preference-Based Policy Iteration Algorithm ###\n",
    "\n",
    "### Functionality:\n",
    "### - INPUTS  : sample states (s'), initial (random) policy (\\pi0), max. num. of policy iterations (p)\n",
    "### - PROCESS : generate roll-out (fixed time horizon) and calculate accumulate reward\n",
    "### - OUTPUT  : compare return from each rollout: store preference info in training dataset as (s,a_k > a_j)\n",
    "\n",
    "\n",
    "# initialize environment\n",
    "env = gym.make('CartPole-v0')\n",
    "\n",
    "# initial random policy\n",
    "policy_init = random_action\n",
    "policy = policy_init\n",
    "\n",
    "# sample states\n",
    "sample_states = generate_init_states_S(seed = 16) # randomly generated states initial\n",
    "\n",
    "# maximum number of policy iterations\n",
    "max_iterr = 1 # increase this after writing the LabelRanker\n",
    "\n",
    "# action space to consider\n",
    "act_space = partition_action_space(env,3)\n",
    "\n",
    "# generate action-pairs (per each)\n",
    "act_pairs = list(itertools.combinations(act_space,2))\n",
    "\n",
    "# place-holder for training data\n",
    "train_data = []\n",
    "\n",
    "iterr = 0\n",
    "\n",
    "pbar = tqdm.tqdm(total=max_iterr)\n",
    "\n",
    "while iterr < max_iterr:\n",
    "    \n",
    "    # place-holder for training data\n",
    "    #train_data = [] # uncomment this after adding LabelRanker\n",
    "\n",
    "    \n",
    "    for state in sample_states:\n",
    "        \n",
    "        for action_pair in act_pairs:\n",
    "            preference_out = evaluate_preference(state, action_pair[0], action_pair[1], policy)\n",
    "            \n",
    "            if preference_out is not None:\n",
    "                train_data.append(preference_out)\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "    pbar.update(1)\n",
    "    iterr += 1\n",
    "    \n",
    "    \n",
    "pbar.close()\n",
    "### Train LaberRanker using train-data\n",
    "### Create new policy using LabeRanker\n",
    "### Re-run loop with new policy\n",
    "\n",
    "        \n",
    "        \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `LABEL-RANKER` Model training Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "epoch:   0 loss: 2.39541817\n",
      "epoch:  25 loss: 0.02365649\n",
      "epoch:  50 loss: 0.09631121\n",
      "epoch:  75 loss: 0.05344461\n",
      "epoch: 100 loss: 0.14437440\n",
      "epoch: 125 loss: 0.03273392\n",
      "epoch: 150 loss: 0.04118802\n",
      "epoch: 175 loss: 0.02512840\n",
      "epoch: 200 loss: 0.02410264\n",
      "epoch: 225 loss: 0.04048956\n",
      "epoch: 250 loss: 0.02288586\n",
      "epoch: 275 loss: 0.07751641\n",
      "\n",
      "Training loss:  0.03327476 \n",
      "\r"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = train_model(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LABEL RANKER (POLICY) ###\n",
    "\n",
    "# This takes the trained model as an input\n",
    "# When a new state is given, the model makes a prediction for each action\n",
    "# This function then rank the actions based on the prediction\n",
    "# I select the Highest ranked (most prefered action) 90% time and second most preferred action 10% time\n",
    "\n",
    "def label_ranking_policy(obs,model):\n",
    "    \n",
    "    state_obs = obs[[2,3]] # only select angel and angular velo. of pendulum from state vector\n",
    "    state_obs = state_obs.reshape(-1,state_obs.shape[0]) # reshape to be a 2D array\n",
    "    state_obs = torch.from_numpy(state_obs) # convert to a tensor\n",
    "\n",
    "    # make the prediction for actions\n",
    "    with torch.no_grad():\n",
    "        preds = model(state_obs.float()) \n",
    "\n",
    "    # rank the indexes of actions (from highest ranked/preferred action to lowest)\n",
    "    ranked_action_idx = (-rd(preds.detach().numpy())).argsort()[:preds.shape[1]]\n",
    "\n",
    "    # return the action value\n",
    "    remain_probs = .1/len(ranked_action_idx[2:])\n",
    "    n_remain_actions = ranked_action_idx.shape[0]-2\n",
    "\n",
    "    # - select first two (highest preferred actions) 80% and 10% of the time\n",
    "    # - select one of the remaining actions 10% time\n",
    "    action = np.random.choice(ranked_action_idx,1 , p=[0.8, 0.1] + list(np.repeat(remain_probs,n_remain_actions)))[0]\n",
    "\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 825,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_ranking_policy(observation,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APPENDIX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TRAINING DATASET PREP + MODEL + TRAINING [BREAKDOWN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>a_j</th>\n",
       "      <th>a_k</th>\n",
       "      <th>preference_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[-0.04042570338131652, 0.2768141014688637]</td>\n",
       "      <td>-0.122154</td>\n",
       "      <td>0.377846</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[-0.04042570338131652, 0.2768141014688637]</td>\n",
       "      <td>-0.122154</td>\n",
       "      <td>0.877846</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[-0.04042570338131652, 0.2768141014688637]</td>\n",
       "      <td>0.377846</td>\n",
       "      <td>0.877846</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        state       a_j       a_k  \\\n",
       "0  [-0.04042570338131652, 0.2768141014688637] -0.122154  0.377846   \n",
       "1  [-0.04042570338131652, 0.2768141014688637] -0.122154  0.877846   \n",
       "2  [-0.04042570338131652, 0.2768141014688637]  0.377846  0.877846   \n",
       "\n",
       "   preference_label  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 0  "
      ]
     },
     "execution_count": 690,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a training dataframe\n",
    "train_df = pd.DataFrame(train_data)\n",
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a key for state\n",
    "train_df.loc[:, 'state_key'] = train_df.state.apply(lambda x: x[0].astype(str)+\"_\"+x[1].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all states which does not have any preferred action\n",
    "temp_df1 = train_df.groupby('state_key').preference_label.sum().reset_index()\n",
    "temp_df1 = temp_df1.loc[temp_df1.preference_label>0] # pick the states that have at least one prefered action\n",
    "train_df = train_df.merge(right = temp_df1.loc[:,'state_key']\n",
    "                          , right_on = 'state_key'\n",
    "                          , left_on = 'state_key'\n",
    "                          , how = 'right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a single column with the set of actions executed per state\n",
    "temp_df1 = train_df.groupby('state_key')['a_j'].unique().reset_index()\n",
    "temp_df2 = train_df.groupby('state_key')['a_k'].unique().reset_index()\n",
    "temp_df3 = temp_df1.merge(right=temp_df2\n",
    "                          , right_on = 'state_key'\n",
    "                          , left_on = 'state_key'\n",
    "                          , how = 'inner')\n",
    "temp_df3.loc[:,'unique_acts'] = temp_df3.apply(lambda row: set(list(row['a_j']) + list(row['a_k'])) ,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_key</th>\n",
       "      <th>a_j</th>\n",
       "      <th>a_k</th>\n",
       "      <th>unique_acts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.007119426465262891_0.010133984961571807</td>\n",
       "      <td>[-0.12215383778081441, 0.3778461622191856]</td>\n",
       "      <td>[0.3778461622191856, 0.8778461622191855]</td>\n",
       "      <td>{-0.12215383778081441, 0.8778461622191855, 0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.035456221985432065_-0.331823583123806</td>\n",
       "      <td>[-0.12215383778081441, 0.3778461622191856]</td>\n",
       "      <td>[0.3778461622191856, 0.8778461622191855]</td>\n",
       "      <td>{-0.12215383778081441, 0.8778461622191855, 0.3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    state_key  \\\n",
       "0  -0.007119426465262891_0.010133984961571807   \n",
       "1    -0.035456221985432065_-0.331823583123806   \n",
       "\n",
       "                                          a_j  \\\n",
       "0  [-0.12215383778081441, 0.3778461622191856]   \n",
       "1  [-0.12215383778081441, 0.3778461622191856]   \n",
       "\n",
       "                                        a_k  \\\n",
       "0  [0.3778461622191856, 0.8778461622191855]   \n",
       "1  [0.3778461622191856, 0.8778461622191855]   \n",
       "\n",
       "                                         unique_acts  \n",
       "0  {-0.12215383778081441, 0.8778461622191855, 0.3...  \n",
       "1  {-0.12215383778081441, 0.8778461622191855, 0.3...  "
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df3.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the unique-action column to train dataset\n",
    "train_df = train_df.merge(right = temp_df3.loc[:,['state_key', 'unique_acts']]\n",
    "              , right_on =  'state_key'\n",
    "              , left_on = 'state_key'\n",
    "              , how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a 'prefered-action' value for each state\n",
    "train_df.loc[:,'prefered_action'] = train_df.apply(lambda row: row['a_j'] if row['preference_label'] == 1 else row['a_k']  ,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>a_j</th>\n",
       "      <th>a_k</th>\n",
       "      <th>preference_label</th>\n",
       "      <th>state_key</th>\n",
       "      <th>unique_acts</th>\n",
       "      <th>prefered_action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[-0.035456221985432065, -0.331823583123806]</td>\n",
       "      <td>-0.122154</td>\n",
       "      <td>0.377846</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.035456221985432065_-0.331823583123806</td>\n",
       "      <td>{-0.12215383778081441, 0.8778461622191855, 0.3...</td>\n",
       "      <td>0.377846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[-0.035456221985432065, -0.331823583123806]</td>\n",
       "      <td>-0.122154</td>\n",
       "      <td>0.877846</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.035456221985432065_-0.331823583123806</td>\n",
       "      <td>{-0.12215383778081441, 0.8778461622191855, 0.3...</td>\n",
       "      <td>-0.122154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         state       a_j       a_k  \\\n",
       "0  [-0.035456221985432065, -0.331823583123806] -0.122154  0.377846   \n",
       "1  [-0.035456221985432065, -0.331823583123806] -0.122154  0.877846   \n",
       "\n",
       "   preference_label                                 state_key  \\\n",
       "0                 0  -0.035456221985432065_-0.331823583123806   \n",
       "1                 1  -0.035456221985432065_-0.331823583123806   \n",
       "\n",
       "                                         unique_acts  prefered_action  \n",
       "0  {-0.12215383778081441, 0.8778461622191855, 0.3...         0.377846  \n",
       "1  {-0.12215383778081441, 0.8778461622191855, 0.3...        -0.122154  "
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>prefered_action</th>\n",
       "      <th>-0.122154</th>\n",
       "      <th>0.377846</th>\n",
       "      <th>0.877846</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state_key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>-0.007119426465262891_0.010133984961571807</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>-0.035456221985432065_-0.331823583123806</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>-0.042092693647908186_-0.635473455421564</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>-0.054802162756339465_-0.9411095238977125</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>-0.07362435323429371_-0.6661375648946086</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "prefered_action                             -0.122154   0.377846   0.877846\n",
       "state_key                                                                  \n",
       "-0.007119426465262891_0.010133984961571807        1.0        1.0        1.0\n",
       "-0.035456221985432065_-0.331823583123806          1.0        2.0        0.0\n",
       "-0.042092693647908186_-0.635473455421564          1.0        2.0        0.0\n",
       "-0.054802162756339465_-0.9411095238977125         2.0        1.0        0.0\n",
       "-0.07362435323429371_-0.6661375648946086          2.0        1.0        0.0"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count the number of times each action is prefered at a state\n",
    "action_preference_counts = train_df.groupby('state_key').prefered_action.value_counts().unstack()\n",
    "action_preference_counts.replace(np.nan,0,inplace=True)\n",
    "action_preference_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "### convert the action-preference-counts to a vector (to be used as training labels)\n",
    "action_preference_counts.loc[:, 'preference_label_vector'] = action_preference_counts.iloc[:,0:].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>prefered_action</th>\n",
       "      <th>-0.12215383778081441</th>\n",
       "      <th>0.3778461622191856</th>\n",
       "      <th>0.8778461622191855</th>\n",
       "      <th>preference_label_vector</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state_key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>-0.007119426465262891_0.010133984961571807</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1.0, 1.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>-0.035456221985432065_-0.331823583123806</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[1.0, 2.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>-0.042092693647908186_-0.635473455421564</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[1.0, 2.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>-0.054802162756339465_-0.9411095238977125</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[2.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>-0.07362435323429371_-0.6661375648946086</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[2.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "prefered_action                             -0.12215383778081441  \\\n",
       "state_key                                                          \n",
       "-0.007119426465262891_0.010133984961571807                   1.0   \n",
       "-0.035456221985432065_-0.331823583123806                     1.0   \n",
       "-0.042092693647908186_-0.635473455421564                     1.0   \n",
       "-0.054802162756339465_-0.9411095238977125                    2.0   \n",
       "-0.07362435323429371_-0.6661375648946086                     2.0   \n",
       "\n",
       "prefered_action                             0.3778461622191856  \\\n",
       "state_key                                                        \n",
       "-0.007119426465262891_0.010133984961571807                 1.0   \n",
       "-0.035456221985432065_-0.331823583123806                   2.0   \n",
       "-0.042092693647908186_-0.635473455421564                   2.0   \n",
       "-0.054802162756339465_-0.9411095238977125                  1.0   \n",
       "-0.07362435323429371_-0.6661375648946086                   1.0   \n",
       "\n",
       "prefered_action                             0.8778461622191855  \\\n",
       "state_key                                                        \n",
       "-0.007119426465262891_0.010133984961571807                 1.0   \n",
       "-0.035456221985432065_-0.331823583123806                   0.0   \n",
       "-0.042092693647908186_-0.635473455421564                   0.0   \n",
       "-0.054802162756339465_-0.9411095238977125                  0.0   \n",
       "-0.07362435323429371_-0.6661375648946086                   0.0   \n",
       "\n",
       "prefered_action                            preference_label_vector  \n",
       "state_key                                                           \n",
       "-0.007119426465262891_0.010133984961571807         [1.0, 1.0, 1.0]  \n",
       "-0.035456221985432065_-0.331823583123806           [1.0, 2.0, 0.0]  \n",
       "-0.042092693647908186_-0.635473455421564           [1.0, 2.0, 0.0]  \n",
       "-0.054802162756339465_-0.9411095238977125          [2.0, 1.0, 0.0]  \n",
       "-0.07362435323429371_-0.6661375648946086           [2.0, 1.0, 0.0]  "
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_preference_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add preference label vector to training dataset\n",
    "train_df = train_df.merge(right = action_preference_counts.loc[:,['preference_label_vector']]\n",
    "                          , right_index= True\n",
    "                          , left_on = 'state_key'\n",
    "                          , how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>a_j</th>\n",
       "      <th>a_k</th>\n",
       "      <th>preference_label</th>\n",
       "      <th>state_key</th>\n",
       "      <th>unique_acts</th>\n",
       "      <th>prefered_action</th>\n",
       "      <th>preference_label_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[-0.035456221985432065, -0.331823583123806]</td>\n",
       "      <td>-0.122154</td>\n",
       "      <td>0.377846</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.035456221985432065_-0.331823583123806</td>\n",
       "      <td>{-0.12215383778081441, 0.8778461622191855, 0.3...</td>\n",
       "      <td>0.377846</td>\n",
       "      <td>[1.0, 2.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[-0.035456221985432065, -0.331823583123806]</td>\n",
       "      <td>-0.122154</td>\n",
       "      <td>0.877846</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.035456221985432065_-0.331823583123806</td>\n",
       "      <td>{-0.12215383778081441, 0.8778461622191855, 0.3...</td>\n",
       "      <td>-0.122154</td>\n",
       "      <td>[1.0, 2.0, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         state       a_j       a_k  \\\n",
       "0  [-0.035456221985432065, -0.331823583123806] -0.122154  0.377846   \n",
       "1  [-0.035456221985432065, -0.331823583123806] -0.122154  0.877846   \n",
       "\n",
       "   preference_label                                 state_key  \\\n",
       "0                 0  -0.035456221985432065_-0.331823583123806   \n",
       "1                 1  -0.035456221985432065_-0.331823583123806   \n",
       "\n",
       "                                         unique_acts  prefered_action  \\\n",
       "0  {-0.12215383778081441, 0.8778461622191855, 0.3...         0.377846   \n",
       "1  {-0.12215383778081441, 0.8778461622191855, 0.3...        -0.122154   \n",
       "\n",
       "  preference_label_vector  \n",
       "0         [1.0, 2.0, 0.0]  \n",
       "1         [1.0, 2.0, 0.0]  "
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>state_key</th>\n",
       "      <th>unique_acts</th>\n",
       "      <th>preference_label_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[-0.035456221985432065, -0.331823583123806]</td>\n",
       "      <td>-0.035456221985432065_-0.331823583123806</td>\n",
       "      <td>{-0.12215383778081441, 0.8778461622191855, 0.3...</td>\n",
       "      <td>[1.0, 2.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[-0.042092693647908186, -0.635473455421564]</td>\n",
       "      <td>-0.042092693647908186_-0.635473455421564</td>\n",
       "      <td>{-0.12215383778081441, 0.8778461622191855, 0.3...</td>\n",
       "      <td>[1.0, 2.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>[-0.054802162756339465, -0.9411095238977125]</td>\n",
       "      <td>-0.054802162756339465_-0.9411095238977125</td>\n",
       "      <td>{-0.12215383778081441, 0.8778461622191855, 0.3...</td>\n",
       "      <td>[2.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          state  \\\n",
       "0   [-0.035456221985432065, -0.331823583123806]   \n",
       "3   [-0.042092693647908186, -0.635473455421564]   \n",
       "6  [-0.054802162756339465, -0.9411095238977125]   \n",
       "\n",
       "                                   state_key  \\\n",
       "0   -0.035456221985432065_-0.331823583123806   \n",
       "3   -0.042092693647908186_-0.635473455421564   \n",
       "6  -0.054802162756339465_-0.9411095238977125   \n",
       "\n",
       "                                         unique_acts preference_label_vector  \n",
       "0  {-0.12215383778081441, 0.8778461622191855, 0.3...         [1.0, 2.0, 0.0]  \n",
       "3  {-0.12215383778081441, 0.8778461622191855, 0.3...         [1.0, 2.0, 0.0]  \n",
       "6  {-0.12215383778081441, 0.8778461622191855, 0.3...         [2.0, 1.0, 0.0]  "
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the reduced training dataset (drop unnecessary columns + duplicate rows: which have data for same state)\n",
    "train_df_reduced = train_df.loc[:,['state', 'state_key', 'unique_acts', 'preference_label_vector']]\n",
    "\n",
    "train_df_reduced.drop_duplicates(subset=['state_key'],inplace=True)\n",
    "train_df_reduced.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# above dataset has - state + list of actions + # preferences made for each action (at state) --> each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_labels_temp = np.array(train_df_reduced.preference_label_vector.tolist())\n",
    "row_sums = output_labels_temp.sum(axis=1)\n",
    "output_labels_normalized = output_labels_temp / row_sums[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training dataset\n",
    "input_states  = torch.from_numpy(np.array(train_df_reduced.state.apply(lambda x: x.astype(float)).tolist()))\n",
    "output_labels = torch.from_numpy(output_labels_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import tensor dataset & data loader\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TensorDataset(input_states , output_labels )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 0.0616,  0.3560],\n",
       "         [ 0.0463,  1.1982],\n",
       "         [-0.0355, -0.3318]], dtype=torch.float64),\n",
       " tensor([[0.3333, 0.0000, 0.6667],\n",
       "         [0.3333, 0.0000, 0.6667],\n",
       "         [0.3333, 0.6667, 0.0000]], dtype=torch.float64)]"
      ]
     },
     "execution_count": 564,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define data loader\n",
    "batch_size = 3\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True, drop_last=True)\n",
    "next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self, input_state_len, output_label_len, layers, p=0.4):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.batch_norm_num = nn.BatchNorm1d(input_state_len)\n",
    "\n",
    "        all_layers = []\n",
    "        input_size = input_state_len\n",
    "\n",
    "        # create layers\n",
    "        for layer_dim in layers:\n",
    "            all_layers.append(nn.Linear(input_size, layer_dim))\n",
    "            all_layers.append(nn.ReLU(inplace=True))\n",
    "            all_layers.append(nn.BatchNorm1d(layer_dim))\n",
    "            all_layers.append(nn.Dropout(p))\n",
    "            input_size = layer_dim\n",
    "\n",
    "        all_layers.append(nn.Linear(layers[-1], output_label_len))\n",
    "\n",
    "        self.layers = nn.Sequential(*all_layers)\n",
    "\n",
    "    def forward(self, state_vec):\n",
    "        x = self.batch_norm_num(state_vec)\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "model = Model(input_states.shape[1], output_labels.shape[1], [100,500,50], p=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.SGD(model.parameters(), lr = 1e-1)\n",
    "loss_fn = F.mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to store losses\n",
    "aggregated_losses = []\n",
    "\n",
    "# Define a utility function to train the model\n",
    "def fit(num_epochs, model, loss_fn, opt):\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        for xb,yb in train_dl:\n",
    "            \n",
    "            # Generate predictions\n",
    "            pred = model(xb.float())\n",
    "            loss = loss_fn(pred, yb.float())            \n",
    "            \n",
    "            # Perform gradient descent\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "            \n",
    "        aggregated_losses.append(loss_fn(model(input_states.float()), output_labels.float()).detach().numpy())\n",
    "        \n",
    "        if epoch%25 == 0:\n",
    "                print(f'epoch: {epoch:3} loss: {loss.item():10.8f}')\n",
    "            \n",
    "    print('Training loss: ', loss_fn(model(input_states.float()), output_labels.float()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   0 loss: 1.26457167\n",
      "epoch:  25 loss: 0.03228344\n",
      "epoch:  50 loss: 0.11356914\n",
      "epoch:  75 loss: 0.03096418\n",
      "epoch: 100 loss: 0.03917579\n",
      "epoch: 125 loss: 0.09606967\n",
      "epoch: 150 loss: 0.03857052\n",
      "epoch: 175 loss: 0.10947236\n",
      "epoch: 200 loss: 0.03288856\n",
      "epoch: 225 loss: 0.12105025\n",
      "epoch: 250 loss: 0.08336683\n",
      "epoch: 275 loss: 0.06543268\n",
      "Training loss:  tensor(0.0267, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "epochs= 300\n",
    "fit(epochs, model, loss_fn, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEJCAYAAACZjSCSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3dd3xcZ53v8c9vinqzLbnbcU1xQqpJBZINYVMoATZZAguEBTaXdoHLFgjsDZALbODFAssGCGFJSEIW0ghrQiCkOQmBOJaN7cQl7kW2bMlFktU1M7/7xzkjy9JIVhyPZfl836+XXpo5c2bmOTrSfPWU8zzm7oiISHTFRroAIiIyshQEIiIRpyAQEYk4BYGISMQpCEREIk5BICIScXkPAjOLm9lfzOyRHI8Vmtl9ZrbezBaZ2Yx8l0dERA52NGoEnwFWD/LYR4B97j4H+C7wzaNQHhER6SORzxc3s6nAW4GvA5/LscvVwFfC2w8Ct5qZ+RBXuVVXV/uMGTOOcElFRI5vS5Ys2e3uNbkey2sQAN8D/gUoH+TxKcA2AHdPmVkzMA7YPdgLzpgxg9ra2iNdThGR45qZbRnssbw1DZnZ24AGd18y1G45tg2oDZjZDWZWa2a1jY2NR6yMIiKS3z6Ci4B3mNlm4JfApWb283771AHTAMwsAVQCe/u/kLvf7u7z3X1+TU3Omo2IiBymvAWBu9/o7lPdfQZwHfCUu7+/324LgOvD29eE+2gWPBGRoyjffQQDmNnNQK27LwB+CtxjZusJagLXHe3yiIhE3VEJAndfCCwMb9/UZ3sncO3RKIOIiOSmK4tFRCJOQSAiEnGRCoKuVJoHareh/mgRkQMiFQTPrd3NPz+4gjU79490UUREjhmRCoLudCb4nsqMcElERI4dkQqCTNgklFbTkIhIr4gFQfA9nVEQiIhkRSoIsp3EqbSCQEQkK1JBkK0JqEYgInJApIIg+/mfyqizWEQkK2JBoBqBiEh/kQqC3j4CBYGISK9IBUF4GYFqBCIifUQqCDKqEYiIDBCpIPDePgJ1FouIZEUqCHpHDek6AhGRXpEKAl1HICIyUN6CwMyKzOxFM1tuZivN7Ks59vmQmTWa2bLw66P5Kg+oj0BEJJd8LlXZBVzq7q1mlgT+aGa/c/cX+u13n7t/Ko/l6JWday6jSedERHrlLQg86JltDe8mw68R/QROa64hEZEB8tpHYGZxM1sGNACPu/uiHLv9jZmtMLMHzWxaPsujK4tFRAbKaxC4e9rdzwSmAuea2Wn9dvkNMMPdTweeAO7K9TpmdoOZ1ZpZbWNj42soT/BdfQQiIgcclVFD7t4ELASu6Ld9j7t3hXd/ApwzyPNvd/f57j6/pqbmsMuRyeg6AhGR/vI5aqjGzKrC28XAZcCafvtM6nP3HcDqfJUH+vQRqEYgItIrn6OGJgF3mVmcIHDud/dHzOxmoNbdFwCfNrN3AClgL/ChPJZHK5SJiOSQz1FDK4Czcmy/qc/tG4Eb81WGHO8NqEYgItJXpK4s1qghEZGBIhUE2WmodR2BiMgBkQoCzT4qIjJQpIJAcw2JiAwUqSDQCmUiIgNFKghUIxARGShSQZDtI8goCEREekUqCDKaa0hEZIBIBUFa1xGIiAwQqSA4cGWxho+KiGRFKggyGjUkIjJAtIJAo4ZERAaIVBCoj0BEZKBIBUHvCmWaa0hEpFekgkCzj4qIDBSpIMgGgEYNiYgcEKkgcK1QJiIyQD7XLC4ysxfNbLmZrTSzr+bYp9DM7jOz9Wa2yMxm5Ks8oFFDIiK55LNG0AVc6u5nAGcCV5jZ+f32+Qiwz93nAN8FvpnH8qiPQEQkh7wFgQdaw7vJ8Kv/J/DVwF3h7QeBN5uZ5atMvSuUKQhERHrltY/AzOJmtgxoAB5390X9dpkCbANw9xTQDIzLV3k0+6iIyEB5DQJ3T7v7mcBU4FwzO63fLrn++x/wKW1mN5hZrZnVNjY2HnZ51EcgIjLQURk15O5NwELgin4P1QHTAMwsAVQCe3M8/3Z3n+/u82tqag67HBmNGhIRGSCfo4ZqzKwqvF0MXAas6bfbAuD68PY1wFOebb/Jg4xmHxURGSCRx9eeBNxlZnGCwLnf3R8xs5uBWndfAPwUuMfM1hPUBK7LY3k0akhEJIe8BYG7rwDOyrH9pj63O4Fr81WG/jIaNSQiMkCkrizunX1Uk86JiPSKVBC4Rg2JiAwQqSDQqCERkYEiFgQaNSQi0l+0giCsCWRcVxeLiGRFKwj6fPan83e5gojIqBKxIDjw4a9+AhGRQMSC4MBtBYGISCBaQdDnw19DSEVEAtEKAjUNiYgMENkg0BBSEZFAxILgwG3VCEREAhELgj41As03JCICRDAIsisiq0YgIhKIVhBkIBkPDlmjhkREAtEKAncKwyBQjUBEJBC5IEgmsjUCjRoSEYH8rlk8zcyeNrPVZrbSzD6TY59LzKzZzJaFXzfleq0jJeOQjAedBOosFhEJ5HPN4hTwj+6+1MzKgSVm9ri7r+q333Pu/rY8lqOXu1OQjAeFU9OQiAiQxxqBu9e7+9Lw9n5gNTAlX+83HOmMU5gIgqAnraYhERE4Sn0EZjaDYCH7RTkevsDMlpvZ78zs1HyWI+NQkB01pKYhEREgv01DAJhZGfAQ8Fl3b+n38FLgBHdvNbOrgF8Dc3O8xg3ADQDTp08/7LJk3ClMBkHQo85iEREgzzUCM0sShMC97v6r/o+7e4u7t4a3HwWSZladY7/b3X2+u8+vqak57PJkMk5hOGqoJ6UgEBGB/I4aMuCnwGp3/84g+0wM98PMzg3LsydfZco4FCTUWSwi0lc+m4YuAj4AvGRmy8JtXwSmA7j7bcA1wMfNLAV0ANe5528NyYx7bx+BOotFRAJ5CwJ3/yNgh9jnVuDWfJVh4PtxoI9AncUiIkDErixO+4E+gpRqBCIiQMSCINMnCHrURyAiAkQoCNw9aBrKXlCmUUMiIkCkgiD4XqhJ50REDhKZIEiHSVCQUGexiEhfkQmC7DKVmmJCRORgkQmCbNNQIh4jZrqOQEQkKzJBkF2RLGZBGGiuIRGRQGSCINs0FI8ZBfGYmoZEREIRCoLgu5mRiJuahkREQpEJguwURjGDRCymUUMiIqHIBMGBPgIjGTdNMSEiEopMEGSbhmIxIxmPqWlIRCQUmSA4qGkobpprSEQkFJkg6K0RmJGMxdQ0JCISGlYQmNlsMysMb19iZp82s6r8Fu3Iyk4xETcjmTB1FouIhIZbI3gISJvZHILlJ2cC/523UuVBJqwSWO+oIdUIRERg+EGQcfcU8C7ge+7+f4BJQz3BzKaZ2dNmttrMVprZZ3LsY2b2fTNbb2YrzOzsV38Iw+N9m4bipgvKRERCw12qssfM3gtcD7w93JY8xHNSwD+6+1IzKweWmNnj7r6qzz5XAnPDr/OAH4Xfj7hs01AsBsl4jG6tRyAiAgy/RvD3wAXA1919k5nNBH4+1BPcvd7dl4a39wOrgSn9drsauNsDLwBVZjZkTeNwZfzAdQTBXEOqEYiIwDBrBOF/8Z8GMLMxQLm73zLcNzGzGcBZwKJ+D00BtvW5Xxduq+/3/BuAGwCmT58+3Lc9iPcJgmRMF5SJiGQNd9TQQjOrMLOxwHLgTjP7zjCfW0bQ2fxZd2/p/3COpwz4V93db3f3+e4+v6amZjhvO8BBw0d1QZmISK/hNg1Vhh/i7wbudPdzgMsO9SQzSxKEwL3u/qscu9QB0/rcnwrsGGaZXpWDp6FWZ7GISNZwgyARtt3/LfDIcJ5gZkYw1HS1uw9We1gAfDAcPXQ+0Ozu9YPs+5r09hFkp5jQegQiIsDwRw3dDDwGPO/ui81sFrDuEM+5CPgA8JKZLQu3fRGYDuDutwGPAlcB64F2gk7pvNDwURGR3IbbWfwA8ECf+xuBvznEc/5I7j6Avvs48MnhlOG1yni/FcrURyAiAgy/s3iqmT1sZg1mtsvMHjKzqfku3JF00DTUMU0xISKSNdw+gjsJ2vMnEwzv/E24bdToOw11Iq5J50REsoYbBDXufqe7p8KvnwGHN45zhPSdhjoYPqoagYgIDD8IdpvZ+80sHn69H9iTz4Idaf1XKNOoIRGRwHCD4MMEQ0d3Elz1ew15HOGTD30vKEvEYrgfCAcRkSgbVhC4+1Z3f4e717j7eHd/J8HFZaPGQU1DiWAwk0YOiYi8thXKPnfESnEUHLRmcSw4bAWBiMhrC4IhrxE41qT7rVkM6KIyERFeWxCMqk/RvtNQJ+OqEYiIZA15ZbGZ7Sf3B74BxXkpUZ4cNA11WCPQmgQiIocIAncvP1oFybfsaNHsqCFAF5WJiPDamoZGlWwfgRkkE2oaEhHJikwQZJuG4rFgriFAVxeLiBChIDjogrJ4tmlIQSAiEqEg6DvXUFAj6FbTkIjIsBemGfXedvpk3vq6SQA0dfQA0N6dGskiiYgcEyITBADB6plQVhgcdmungkBEJG9NQ2Z2R7iQzcuDPH6JmTWb2bLw66Z8laW/bBDs71IQiIjks0bwM+BW4O4h9nnO3d+WxzLklA2CNgWBiEj+agTu/iywN1+v/1qUqmlIRKTXSI8ausDMlpvZ78zs1MF2MrMbzKzWzGobGxtf85sWJGIUJmK0qkYgIjKiQbAUOMHdzwD+E/j1YDu6++3uPt/d59fUHJkVMsuLEgoCERFGMAjcvcXdW8PbjwJJM6s+Wu9fWqggEBGBEQwCM5to4XhOMzs3LMtRWwe5rDChPgIREfI4asjMfgFcAlSbWR3wZSAJ4O63Eax7/HEzSwEdwHWenRDoKCgrTGj4qIgIeQwCd3/vIR6/lWB46YgoL0pQ39w5Um8vInLMGOlRQyNGfQQiIoHIBoH6CEREAtENAg0fFREBohwEBQm6Uhm6U5qKWkSiLbpBUKT5hkREIMpBkJ1vSEEgIhEX2SAoL1IQiIhAhIMgOwPpfo0cEpGIi2wQVBQlAdjf2TPCJRERGVnRDYLiIAhaFAQiEnGRDYLKMAia2xUEIhJtkQ2CbGdxi/oIRCTiIhsEyXiMkoI4LR2qEYhItEU2CCDoMFYfgYhEXaSDoLI4SbNqBCIScZEOgoriBC0d6iMQkWiLdhCoaUhEJH9BYGZ3mFmDmb08yONmZt83s/VmtsLMzs5XWQZToaYhEZG81gh+BlwxxONXAnPDrxuAH+WxLDlVFic1akhEIi9vQeDuzwJ7h9jlauBuD7wAVJnZpHyVJ5eKomAB+0zGj+bbiogcU0ayj2AKsK3P/bpw2wBmdoOZ1ZpZbWNj4xErQEVxEndo7VaHsYhE10gGgeXYlvNfc3e/3d3nu/v8mpqaI1aA7MRzmmZCRKJsJIOgDpjW5/5UYMfRLIAmnhMRGdkgWAB8MBw9dD7Q7O71R7MAFdn5hnQtgYhEWCJfL2xmvwAuAarNrA74MpAEcPfbgEeBq4D1QDvw9/kqy2CKC+IAdPQoCEQkuvIWBO7+3kM87sAn8/X+w5ENgs6ezEgWQ0RkREX6yuKiRFgj6E6PcElEREZOpIOgt0aQUhCISHRFOghUIxARiXoQFASH35VSH4GIRFekg6AgHiNmuWsEXak0/3B3LWt37R+BkomIHD2RDgIzoygZp7NnYBBs39fB46t2sXjzUNMliYiMfpEOAoDiZJyOHEHQHtYSujS0VESOc5EPgqBGMPDDvjcI1H8gIsc5BUEylrNpqC2ckbRLQ0tF5DinIBikj6C9SzUCEYmGyAdBcTKe84KybI0gV0iIiBxPIh8ERcl4zuGjHeojEJGIUBAM0lnc20egUUMicpxTEAzSWXygj0BNQyJyfIt8EBQP0ll8YNSQagQicnyLfBAUDXZBmUYNiUhERD4IigsGuaAsDAeNGhKR411eg8DMrjCzV8xsvZl9IcfjHzKzRjNbFn59NJ/lyaUoEaOjJ02wYNoB7V1qGhKRaMjnmsVx4AfAW4A6YLGZLXD3Vf12vc/dP5WvchxKUbg4TVcqQ1Ey3rv9wKgh1QhE5PiWzxrBucB6d9/o7t3AL4Gr8/h+hyW7OM2WPe1cdMtTrNrRAhyYa6hbNQIROc7lMwimANv63K8Lt/X3N2a2wsweNLNpuV7IzG4ws1ozq21sbDyihcwuV/n8+t1sb+rghY17AE06JyLRkc8gsBzbvN/93wAz3P104Angrlwv5O63u/t8d59fU1NzRAtZHDYHrahrAmDj7lagbx+BmoZE5PiWzyCoA/r+hz8V2NF3B3ff4+5d4d2fAOfksTw5FSWDH8GKumYANja2AdDWnR01pBqBiBzf8hkEi4G5ZjbTzAqA64AFfXcws0l97r4DWJ3H8uSU7SDeuDsIgE3h93ZNQy0iEZG3UUPunjKzTwGPAXHgDndfaWY3A7XuvgD4tJm9A0gBe4EP5as8g+k7UqgoGaO+uZPmjh560k5BPEZ3OkM648RjuVq6RERGv7wFAYC7Pwo82m/bTX1u3wjcmM8yHMq8yRW9y1VefGINj63cxcrtQTPRmNIku1q66E5lejuVRUSON3kNgtGgoijJCze+mV8v287Z08fw2Mpd/GVb0HE8trSQXS1ddKXSCgIROW5FfooJgMqSJNdfOIN5kysoLYjz0JI6AGZVlwLqMBaR45uCoI94zDhjWhUbd7eRjBsXzhkHqMNYRI5vCoJ+zp4+BoAzp1VRVVwA6KIyETm+KQj6OeeEIAgumF1NYSL48WiVMhE5nikI+jlv1ljedvok3n3WFArDi83UNCQix7PIjxrqr6Qgwa3vOxuAhv3BRc99m4ZS6QzxmGGm6wpE5PigGsEQstNPZBen6U5lOP/fnuSB2rqRLJaIyBGlIBhCYeLAWgUAO5o62N3azeLNe0eyWCIiR5SCYAi9ncVhH8G2fe0AbGhsHbEyiYgcaQqCIWTnIWoM+wrq9nUAsKGxbcDSliIio5WCYAgTKgo5c1oVtz+7keaOHrbtDWoEzR097G7tHuHSiYgcGQqCIZgZX3vnaext6+brv13VWyOAwZuHulJp0hnVFkRk9FAQHMJpUyr52MWzub+2jgXLdzBjXAkA6xuCIOj7od/Zk+by7z7Lv/765SFf87cr6vn1X7a/qnKs3NHMdx5fqyYpETniFATD8NnLTmTu+DIgmHpiQkUhT67exZY9bVx4y5N87J4ldPakufP5zWze084Dtduobz5Qe/jhwvXc88IWAPa2dfMvDy7na79dxe9equfeRVuGVYYfLdzA959cx8odLb3b3J3tTR1DPGt0e2ZtI2/5zjPsbevmlZ37+fDPFrOnNeiv6U5leHZto2pfIkeAgmAYChIxvvTWUwCoLE7yt/OnsXBtI+/7ySLautI8tmonF93yFN96bA3nnDAGB/7zqfV86/druOV3a/j2Y6/w/x5ZRX1zBz9+dgNt3Wl2t3bzufuX85UFK/nGo6v50J0vsnTrvpzv35VKs/CVRgB+s+LAap8/XLiBi255isdX7TrkMQxWk8i1/UjXOrbuaeflcI2HV+PhpXWsa2jlrj9t5hcvbuWpNQ18/dFgEbtv/X4NH7zjRX7w9PpDvk5PuLjQfz23kS172l5VGdydu/+8mT+s3Pmqy/9aNLf38P0n19HRffSuas9kfNTVODu606OuzMciy+cP0cyuAP6DYIWy/3L3W/o9XgjcTbBW8R7gPe6+eajXnD9/vtfW1uanwIfwxKpdnHPCGNp70rzxm08xrqyQn3xwPh3dae58fhMzqkv51KVz+N7j67jj+U29zytOxkllMpw7cyyLN+3j/NnjeHZt40GvnYgZDlx9xmS27m3HgU/+1WwM48XNe/nRwg2MKUnS0ZPmpIkV3PLu1/Hen7xAU3sP5UUJ/umvT+K5dbupb+4glXa+cOXJ/NXJ4wF4cvUubvzVS3z3PWeScecrC1byvvNOYGZ1Cf/8wAo+/ea5TKkqZuPuVs6aPobP3b+MN8yp5jNvPpF/fnA540oL+OgbZ3HalErueWELRYkYbz9jcu+oqp3NnTz6Uj3PrmuksyfNnPFlzKkpIxYzipNxvv2HV2jtTPHMv/wV1WWFpNIZ2rrSVJYkAXh+/W7uXbSF6rJCDGjtSvO1d57GG7/1FLtbu6ksTlKUjNHU3kNXKsPsmlI27m6jqjhJS2eKr7x9HmdOG8Oc8WWs3bWflTtaeN2USuaML+MHT6/n9mc3ct6ssTy3bjczq0t5+BMXUlVSMKxz/q3fr+GHCzeQjBt3ffhcLpxdPWCfn7+whW372pk3qYL27jTXvX4aZsaOpg5W7Wjh9TPHUpiIkYzHiMeMun3tLNvWxBWnTqQ7naFuXwcnTigHgiVSl25ponbLXr73xDo+ccls/tfFs6ksTtLalWJjYyunTq4csGJeTzrDPX/ewhWnTWRyVXHOY/nTht0s29bE1DElXHxiDZXFwc//9y/vxN259en1FCXjfP6Kk5k6ppia8kIAkvH8/r+YSmdYvHkfr58xhsSreK8dTR1c+R/PMbO6lK+/6zROnVw5YJ+O7jSJuNHU3kNRMkZZYYIfLtxARXGSD5x/wiHfw93JOAf9vB9ftYvvPbGWGeNKufnqUxlXVjjsMg+mub2Hbzy6mg+/YSYnTSzH3Y/47AVmtsTd5+d8LF9BYGZxYC3wFoKF7BcD73X3VX32+QRwurt/zMyuA97l7u8Z6nVHMgj6Wr6tiSljiqnO8UvQlUrzD3cvYfrYYkoLE8wYV0pbV4qv/XY1lcVJnvzHi/m7nyxiR3MH55wwhnW7Wnno4xfyjUdX88zaRmaMK2FnSye7Wrp6X3NcaQHfvvYMbntmA2t27qe5oweAH7zvbP79D6+wcXcbkyqLOGVSBdv2trOuoZUpVcV0pTI0tXeTyjhVJUn2d6YoKYizvzNYkzm7HGdfBYkY3akMZpCMxShMxGjtTnHVaZP47Uv1vfuVFyW45KTx/HFdI/vae5hVU0pVcZL1Da20hK8PkIwbGYfLT53ARXOq+elzm9i4u41xpQXMqill1Y4WChIx0hmnO52hsyfDeTPHsmjTXv7hjTO5+89b6EpluOXdr6OzJ80Tqxs4cUI5H7t4Fp+7fzl/XL875zlKxo2etDNtbDHb9nZwwrgStu/roLI4yWcvm0vGYdvedi6bN4Hx5YWsqm/hvxdtJfv3d8K4Uv570VbefdYUlmzdx5Y97bxhTjWXnzqB2i37WFHXjHFgveuskyeWM3VMMSvqmnunKQEoL0zw+plj+fOGPXT0pJlYUURrV4rWrhTvO286Te3drK7fz6ZwGvRUxsn+eZ48sZyNu9voTmW4cPY4ChMx3nnWFMaUFFBdVsidz2/igSV1nDq5gm9fewZ3/3kLEyoK+et5E3lh4x5e2t7Mw336pRIxY3x5ITNrSnl+/Z7en5eZ0Z0KplEpTsYx4PLTJrKjqYPuVIZb33c2MYPldc2kwt+b+2u3sb8zRU15Icu2NXHpyeNJxmPU7etgxrgS0u4YRmEyxoaGViqKk3zuLSfS3NFDW1eKexdt5eG/bOeyUyZw8Uk1jC0pYFV9My9tb2FcaQFnTK2ksbWL+SeM5bxZY1ld30J3yrntmQ0s2rSHssIEe9u6+dv503CH/V09zJtUwYzqUr76m1XEzdjX3s2YkgLOmzWW/1m2AzO46W3zmDqmhGXb9tHVk+HUKRWk0k5P2lnf0MrEykIWb97HX7Y28YUrT+aluiaW1zWzs7kTs6CZd1JlEbd/cD7xmFEQj9HalWLtrv1MH1vCki37+PGzG5lSVcwZUys5aWIFj6/aydQxJVxzzlRm1pTy6Ip6nljdQH1zByt3tHDGtCo+eclsPv/QCi6YPY43zKnhDXOqadjfSVVJktk1ZYcdECMVBBcAX3H3y8P7NwK4+7/12eexcJ8/m1kC2AnU+BCFOlaC4HAs2riHwmScM6dV8acNu2nrCpbHTGUylBQcPO3T/s4elm9rpigZY8qYYqqKC3pXSXt5ezO/XLyVt8ybyMUn1tDc3sPCtQ1cfupEipJxOnvS3Ld4Gy9u3ktFUYKK4iTnTB/DZ365jHeeNZkvXnUKS7bsY0dTJxefVMOPFq7n3JnjmDu+jC8vWMn1F8xgfEUh9y/exltPn8RZ08fwjd+u5r7abcysLuWLV53C2l372bKnjYeWbmdcaQF3f+RcTp5YAQT/RTXu7yLjsHpnC8lYjD9t2M0PF24AYO74Mt5xxmR2NHewdEsT+zt7+NUnLmJiZRHuzveeWMd/PLmOZNx4/vOXsmjTXv7ruY3c9eFzB/wnn844izbuYV97D2t2tjB3QjmnTq5g2dYmlm7dx1tPn8RpUyr52iOruP7CGWQy8NXfrKR2S9AMl4gFH7hZkyqLGFtaQE86w9pdrUyuLOLxz11MKu3c++IW7vrTZna1dFFelOBNc2vo6Ekzd3wZV75uEvvaulnXsJ8nVzewbW87qYzzpbeewq6WTtIZeGVnS29t5YLZ41i4tpGKoiSN+zt5YnUDU6qKqSxOUlaY4MXNe7n56lPZ2NhGWWGCRZv2cPrUKkoLE/znU+uoLE7S1N5z0M/i0pPH89SaBiAI8550pjdISgriXHvOVP7p8pNYu2s/T61poL6pk6deaeD0qVW8Zd4Epo4pZtqYEjY2trJkyz72d6Xo6snwh5U7ScSNzp4MHT0Dm6qmVBVjBrtaOjl/1jiWbtlHKuNMHVPM9qYOkrEYaXc6e9LMqilj+74OOlNp+v6VX3xiDc+tayR7KuIx48QJ5exp7TooTPv717eewrXnTOM7j7/CL17cRlEyRnVZYW84T6kqZmZ1KWNLC3hpezM7mjq4dv5UXti4t3fAR8yC9+tJHyhQaUGctu40ZjBtTAlb97ZjBiXJYPt9N5xPIh7jI3ctHnAe+jpv5lgAXtreTHt3msmVRTR19NDep8lvSlUxe9q6epfKBZgxroT65s4BU+B/+KKZ3PT2eYO+31BGKgiuAa5w94+G9z8AnOfun+qzz8vhPnXh/Q3hPrn/xWN0B8FIS2d8QJPCcLk7j6yo55RJFcwJO84hGD1VXpRgQkXRIV9jZ3MnrV0pZteUHvRfTa5q8I6mDnrSGU4YV3pY5R2Ku/Pipr2MryhiQkUhd/1pC6WFcc6YWkR1X9kAAAh1SURBVMXJk8opTMRxd/6wahfTxpQwb3JF73NT6Qx72rLNVYMvX5rJOKmMU5A4dFNHOuNs3dvOjHElmBktnT08vaaBt50+Oef5aunsoSgR57GVOxlTUsDu1i7mjC/jtCmV/GXrPlbVt3DxiTUkYjGefqWBeZMqOGNa1aDvbUBsiN+LbO1wQ2MrT61poCgR5/SplWQc2rpSvOnEGtIZp6mjm/HlRb3H3/c13YOfRzIeY3V9C/ct3sbpUyupLitkXFkB8yZV0NKZorMnza6WTmbXlFFamMDdqdvXwdjSAv60IajZnDShnIriBDOrS5k6pqT3PVq7UhTEYxQkYjTs72RTYxsnT6zobYLs28zT2ZNm8542unoy1JQXUpCIsae1m3jMcHfmjC9jXUMr+zt7OH1qFat2tFBaGCceC8p/1esmAbBpdxuPvlTPpMoiUhknETNOmlhOfVMnhckYF82uJhYzOrrTrKpv4YyplbT3pPn9yzupb+rkDXOrOXt6FWZGJuP8fNEWyosSXHHqJDLu7Grp5DfL65k6ppjudIa548uYP2PsIX+nchmpILgWuLxfEJzr7v+7zz4rw336BsG57r6n32vdANwAMH369HO2bBneSBsREQkMFQT57AWqA6b1uT8V2DHYPmHTUCUwYEY3d7/d3ee7+/yampo8FVdEJJryGQSLgblmNtPMCoDrgAX99lkAXB/evgZ4aqj+AREROfLytjCNu6fM7FPAYwTDR+9w95VmdjNQ6+4LgJ8C95jZeoKawHX5Ko+IiOSW1xXK3P1R4NF+227qc7sTuDafZRARkaHpymIRkYhTEIiIRJyCQEQk4hQEIiIRl9dJ5/LBzBqBw72irBoY9KrlUUbHcmzSsRybdCxwgrvnvBBr1AXBa2FmtYNdWTfa6FiOTTqWY5OOZWhqGhIRiTgFgYhIxEUtCG4f6QIcQTqWY5OO5dikYxlCpPoIRERkoKjVCEREpJ/IBIGZXWFmr5jZejP7wkiX59Uys81m9pKZLTOz2nDbWDN73MzWhd/HjHQ5czGzO8ysIVyIKLstZ9kt8P3wPK0ws7NHruQDDXIsXzGz7eG5WWZmV/V57MbwWF4xs8tHptQDmdk0M3vazFab2Uoz+0y4fdSdlyGOZTSelyIze9HMlofH8tVw+0wzWxSel/vCGZ0xs8Lw/vrw8RmH9cbuftx/Ecx+ugGYBRQAy4F5I12uV3kMm4Hqftu+BXwhvP0F4JsjXc5Byv4m4Gzg5UOVHbgK+B1gwPnAopEu/zCO5SvAP+XYd174u1YIzAx/B+MjfQxh2SYBZ4e3ywnWF583Gs/LEMcyGs+LAWXh7SSwKPx53w9cF26/Dfh4ePsTwG3h7euA+w7nfaNSIzgXWO/uG929G/glcPUIl+lIuBq4K7x9F/DOESzLoNz9WQYuODRY2a8G7vbAC0CVmU06OiU9tEGOZTBXA7909y533wSsJ/hdHHHuXu/uS8Pb+4HVwBRG4XkZ4lgGcyyfF3f31vBuMvxy4FLgwXB7//OSPV8PAm+2/uu+DkNUgmAKsK3P/TqG/kU5FjnwBzNbEi7dCTDB3esh+GMAxo9Y6V69wco+Ws/Vp8Imkzv6NNGNimMJmxPOIvjvc1Sfl37HAqPwvJhZ3MyWAQ3A4wQ1liZ3T4W79C1v77GEjzcD417te0YlCHIl5GgbLnWRu58NXAl80szeNNIFypPReK5+BMwGzgTqgX8Ptx/zx2JmZcBDwGfdvWWoXXNsO9aPZVSeF3dPu/uZBMv7nguckmu38PsROZaoBMFw1k8+prn7jvB7A/AwwS/Irmz1PPzeMHIlfNUGK/uoO1fuviv8480AP+FAM8MxfSxmliT44LzX3X8Vbh6V5yXXsYzW85Ll7k3AQoI+gioL1nWHg8s7rHXfDyUqQTCc9ZOPWWZWambl2dvAXwMvc/Caz9cD/zMyJTwsg5V9AfDBcJTK+UBztqniWNWvrfxdBOcGgmO5LhzZMROYC7x4tMuXS9iO/FNgtbt/p89Do+68DHYso/S81JhZVXi7GLiMoM/jaYJ13WHgeXnt676PdC/50foiGPWwlqC97UsjXZ5XWfZZBKMclgMrs+UnaAt8ElgXfh870mUdpPy/IKia9xD8B/ORwcpOUNX9QXieXgLmj3T5h3Es94RlXRH+YU7qs/+XwmN5BbhypMvfp1xvIGhCWAEsC7+uGo3nZYhjGY3n5XTgL2GZXwZuCrfPIgir9cADQGG4vSi8vz58fNbhvK+uLBYRibioNA2JiMggFAQiIhGnIBARiTgFgYhIxCkIREQiTkEgchSZ2SVm9shIl0OkLwWBiEjEKQhEcjCz94fzwi8zsx+HE4G1mtm/m9lSM3vSzGrCfc80sxfCyc0e7jOH/xwzeyKcW36pmc0OX77MzB40szVmdu/hzBYpciQpCET6MbNTgPcQTPR3JpAG/g4oBZZ6MPnfM8CXw6fcDXze3U8nuJI1u/1e4AfufgZwIcEVyRDMjvlZgnnxZwEX5f2gRIaQOPQuIpHzZuAcYHH4z3oxweRrGeC+cJ+fA78ys0qgyt2fCbffBTwQzg01xd0fBnD3ToDw9V5097rw/jJgBvDH/B+WSG4KApGBDLjL3W88aKPZ/+2331DzswzV3NPV53Ya/R3KCFPTkMhATwLXmNl46F3H9wSCv5fsDJDvA/7o7s3APjN7Y7j9A8AzHsyHX2dm7wxfo9DMSo7qUYgMk/4TEenH3VeZ2b8SrAgXI5hp9JNAG3CqmS0hWAnqPeFTrgduCz/oNwJ/H27/APBjM7s5fI1rj+JhiAybZh8VGSYza3X3spEuh8iRpqYhEZGIU41ARCTiVCMQEYk4BYGISMQpCEREIk5BICIScQoCEZGIUxCIiETc/wf45NYSTpwTHAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(epochs), aggregated_losses)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label Ranking Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 821,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make('CartPole-v0')\n",
    "observation = env.reset()\n",
    "\n",
    "state_obs = observation[[2,3]] # only select angel and angular velo. of pendulum from state vector\n",
    "state_obs = state_obs.reshape(-1,state_obs.shape[0]) # reshape to be a 2D array\n",
    "state_obs = torch.from_numpy(state_obs) # convert to a tensor\n",
    "\n",
    "# make the prediction for actions\n",
    "with torch.no_grad():\n",
    "    preds = model(state_obs.float()) \n",
    "    \n",
    "# rank the indexes of actions (from highest ranked/preferred action to lowest)\n",
    "ranked_action_idx = (-rd(preds.detach().numpy())).argsort()[:preds.shape[1]]\n",
    "\n",
    "# return the action value\n",
    "remain_probs = .1/len(ranked_action_idx[2:])\n",
    "n_remain_actions = ranked_action_idx.shape[0]-2\n",
    "\n",
    "# - select first two (highest preferred actions) 80% and 10% of the time\n",
    "# - select one of the remaining actions 10% time\n",
    "action = np.random.choice(ranked_action_idx,1 , p=[0.8, 0.1] + list(np.repeat(remain_probs,n_remain_actions)))[0]\n",
    "\n",
    "action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize episode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### METHOD 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <video width=\"360\" height=\"auto\" alt=\"test\" controls><source src=\"data:video/mp4;base64,AAAAIGZ0eXBpc29tAAACAGlzb21pc28yYXZjMW1wNDEAAAAIZnJlZQAACNRtZGF0AAACoQYF//+d3EXpvebZSLeWLNgg2SPu73gyNjQgLSBjb3JlIDE2MSAtIEguMjY0L01QRUctNCBBVkMgY29kZWMgLSBDb3B5bGVmdCAyMDAzLTIwMjAgLSBodHRwOi8vd3d3LnZpZGVvbGFuLm9yZy94MjY0Lmh0bWwgLSBvcHRpb25zOiBjYWJhYz0xIHJlZj0zIGRlYmxvY2s9MTowOjAgYW5hbHlzZT0weDM6MHgxMTMgbWU9aGV4IHN1Ym1lPTcgcHN5PTEgcHN5X3JkPTEuMDA6MC4wMCBtaXhlZF9yZWY9MSBtZV9yYW5nZT0xNiBjaHJvbWFfbWU9MSB0cmVsbGlzPTEgOHg4ZGN0PTEgY3FtPTAgZGVhZHpvbmU9MjEsMTEgZmFzdF9wc2tpcD0xIGNocm9tYV9xcF9vZmZzZXQ9LTIgdGhyZWFkcz0xMiBsb29rYWhlYWRfdGhyZWFkcz0yIHNsaWNlZF90aHJlYWRzPTAgbnI9MCBkZWNpbWF0ZT0xIGludGVybGFjZWQ9MCBibHVyYXlfY29tcGF0PTAgY29uc3RyYWluZWRfaW50cmE9MCBiZnJhbWVzPTMgYl9weXJhbWlkPTIgYl9hZGFwdD0xIGJfYmlhcz0wIGRpcmVjdD0xIHdlaWdodGI9MSBvcGVuX2dvcD0wIHdlaWdodHA9MiBrZXlpbnQ9MjUwIGtleWludF9taW49MjUgc2NlbmVjdXQ9NDAgaW50cmFfcmVmcmVzaD0wIHJjX2xvb2thaGVhZD00MCByYz1jcmYgbWJ0cmVlPTEgY3JmPTIzLjAgcWNvbXA9MC42MCBxcG1pbj0wIHFwbWF4PTY5IHFwc3RlcD00IGlwX3JhdGlvPTEuNDAgYXE9MToxLjAwAIAAAAIGZYiEACf//vWxfApqyfOKDOgyLuGXJMmutiLibQDAAY82AAADAABEaliezICUal8AAAMAQkANQH0GUHmImKsVAltEcCYoAEJAT5weTsMg/A+TY1HRer5XvqM61zANd/wJe1KBPUL99JcokWi0JF1/9Pp85fy/VsDwnqEuowZmhgstiAdR0z4oltVZwfuQK5PNxY4FjYDAAQSvIUfyToU897pjfmf3TWxo2tPmcWgO+ewEXiuEPAkBfVdeBWBbE+yFuT0QF/uRVs/EmTrflnpfJ/ys0D/Tl0IdcuAFFMUAnc0b2/lD/TcO19q6ufCKMEApsR39kYgCko1NO/+syCEF5RDRr+aXtfaoZgmZoA0xP5iein99izQu+33yBTIXQdb5ELntP0Ah1UTbLaD3W834BLWRl3MKFOploFswpyPRshGgGQ3aMXulbyajZTazrE3Kw8Lx8V4w0RR5MK6c1oYfRwDfRu0L5mztDIyCwS9or8J4MSwBMrM2h0IqzmEjfNLaj43ZJTuD3OCENzrtO34pvf9i5Ezb5C7ZfFJLu1mxqpjYffE8FxCskX50N5YAIOzRZ1OxBWKUvBzrFAEkdKzeWRFpbmEvyYOAJvlsmmeaAEHom6NthGpPmW6VcU0mfa09GL4xtUlP/btrnbDVBNuGIoe07JH5azfSVjCLHHAAAAMAAAMANWEAAACPQZokbEI//eEAAAQz5YIzWgSANnceNVf4KIt+qRUXwfJFRE2fjOP5l7DzmCKph1EBRbPhe+aLYJF7cm3pkPkmshJLc4AX+h8W+HMhcjXJy/TjjZQ3juEhjv70IUAJo2EB6x54NEhVoiMh/oOxdNgeJcX7+SFOMG76aOTQ4Oc/3v4+eIWJhiTTiYLLMtNDdnkAAABHQZ5CeIR/AAAXQ0criDKsFCBP0k6TIS0th5T/cD9PUlQ9RxBOzu6Gn68UqBSEW6MUAAlxjwPgpyOjtaYmmuGtdbHyLI0KPtkAAAApAZ5hdEf/AAAkwmABUJDPoixJuLn6bmUxNZziUx+lRoXVYYKUsyM4bMAAAABJAZ5jakf/AAAkvuJepIPrgRws43FfGOoy3om5gWudRfinKPTsp32JuH6/xDGoP12M1ACT1XXjpJYzCdCtYyh1kTTa2AJqX+pnwQAAALRBmmhJqEFomUwIR//94QAABDSynaSUALABx+2aFHAw8tgSd8SWmqkRueJEfVqt0qsTDEuaehodqhJ6c+9Vutg9+zRygtEWQb7Ew8jJizEXkgjcqE0HIsO0+ltr3t//uYcCXnm0cRU0JewblSJmXmAhFlXzS0OCXiQigOYyas3TljjyA4eyEN9JWQ5YyPsgz6ONrkMKEOfMVPcRStDLncBAgy4GFOP9pzxtPpARJKgLIjNoUMEAAABvQZ6GRREsI/8AABdQMVRGjSPCGIJtu49SkQuymYESnoPX7NKbftRpHhHvTJ/dCwimRyS+zVrYXq2v71Oo0AmY9qgBB5dinWlQPzlpc4hF9qrOgbAGi2GKIfaEP7ln/4IJINEKbkwmWa3xlho5QvoxAAAAXAGepXRH/wAAJMC0qQgBYWM0muPFmgNuF40jAHptf1cSQDlpPuLIzleDgXmdQbbh2X4VNhhK0+4v1VaRg1w5bI+bzDrv22no+lenLxKUFEuKDsx+X9e6/pDNiHLBAAAASwGep2pH/wAAJJ/Ug7u9ZkJazCtQSu2Ur+KuYvW6ePSGLkoIPvPTf1erNUghJsqFBrJ9Wpo6p8YqKNR7UDlCQ5Wvl11LYDQq24cFgAAAAJJBmqpJqEFsmUwUTH/8hAAAEFFTeNqvktP6psBQL30AFw+/6/iaauX193csCRddc+w3ODpWAGMhqLsgj+XzQN+akORNgbUF+31Bl3GoQ0BsfT+lP68CoSm7nT7oSwelnZn67wHY/umcorwD6WkXz6cw/xwNYsdovn6c/GZmx9u6aGPw8X9RQQyBeNGbD+sQjIUmiAAAAFEBnslqR/8AACRDsOf82oRfpuVS3e5VH4LTOYlwHDBObNo5kVkhqvjEXQNyUOAm9yUR/0tQ3j6TAgNoZmcWx5+LsTJtBdR90w7pXrZbjeu+BNkAAAObbW9vdgAAAGxtdmhkAAAAAAAAAAAAAAAAAAAD6AAAANwAAQAAAQAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgAAAsV0cmFrAAAAXHRraGQAAAADAAAAAAAAAAAAAAABAAAAAAAAANwAAAAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAABAAAAAAlgAAAGQAAAAAAAkZWR0cwAAABxlbHN0AAAAAAAAAAEAAADcAAACAAABAAAAAAI9bWRpYQAAACBtZGhkAAAAAAAAAAAAAAAAAAAyAAAACwBVxAAAAAAALWhkbHIAAAAAAAAAAHZpZGUAAAAAAAAAAAAAAABWaWRlb0hhbmRsZXIAAAAB6G1pbmYAAAAUdm1oZAAAAAEAAAAAAAAAAAAAACRkaW5mAAAAHGRyZWYAAAAAAAAAAQAAAAx1cmwgAAAAAQAAAahzdGJsAAAAnHN0c2QAAAAAAAAAAQAAAIxhdmMxAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAAlgBkABIAAAASAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGP//AAAANmF2Y0MBZAAf/+EAGWdkAB+s2UCYM+XhAAADAAEAAAMAZA8YMZYBAAZo6+PLIsD9+PgAAAAAGHN0dHMAAAAAAAAAAQAAAAsAAAEAAAAAFHN0c3MAAAAAAAAAAQAAAAEAAABoY3R0cwAAAAAAAAALAAAAAQAAAgAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAAAwAAAAABAAABAAAAABxzdHNjAAAAAAAAAAEAAAABAAAACwAAAAEAAABAc3RzegAAAAAAAAAAAAAACwAABK8AAACTAAAASwAAAC0AAABNAAAAuAAAAHMAAABgAAAATwAAAJYAAABVAAAAFHN0Y28AAAAAAAAAAQAAADAAAABidWR0YQAAAFptZXRhAAAAAAAAACFoZGxyAAAAAAAAAABtZGlyYXBwbAAAAAAAAAAAAAAAAC1pbHN0AAAAJal0b28AAAAdZGF0YQAAAAEAAAAATGF2ZjU4LjQ1LjEwMA==\" type=\"video/mp4\" /></video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 698,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make('CartPole-v0')\n",
    "env = wrappers.Monitor(env, \"./gym-results\", force=True)\n",
    "env.reset()\n",
    "for _ in range(1000):\n",
    "    action = env.action_space.sample()\n",
    "    observation, reward, done, info = env.step(action)\n",
    "    if done: break\n",
    "env.close()\n",
    "\n",
    "video = io.open('./gym-results/openaigym.video.%s.video000000.mp4' % env.file_infix, 'r+b').read()\n",
    "encoded = base64.b64encode(video)\n",
    "HTML(data='''\n",
    "    <video width=\"360\" height=\"auto\" alt=\"test\" controls><source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" /></video>'''\n",
    ".format(encoded.decode('ascii')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### METHOD 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 19 finished after 8 timesteps. Total reward: 8.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nb_episodes = 20\n",
    "nb_timesteps = 100\n",
    "img = plt.imshow(env.render(mode='rgb_array')) # only call this once\n",
    "\n",
    "for episode in range(nb_episodes):  # iterate over the episodes\n",
    "    state = env.reset()             # initialise the environment\n",
    "    rewards = []\n",
    "    \n",
    "    for t in range(nb_timesteps):    # iterate over time steps\n",
    "        #env.render()                 # display the environment\n",
    "        img.set_data(env.render(mode='rgb_array')) # just update the data\n",
    "        display.display(plt.gcf())\n",
    "        display.clear_output(wait=True)\n",
    "        state, reward, done, info = env.step(0)  # implement the action chosen by the policy\n",
    "        rewards.append(reward)      # add 1 to the rewards list\n",
    "        \n",
    "        if done: # the episode ends either if the pole is > 15 deg from vertical or the cart move by > 2.4 unit from the centre\n",
    "            cumulative_reward = sum(rewards)\n",
    "            print(\"episode {} finished after {} timesteps. Total reward: {}\".format(episode, t+1, cumulative_reward))  \n",
    "            break\n",
    "    \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### OTHER USEFUL-INFO:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "- useful links\n",
    "    - how to initialize to a custom state: https://stackoverflow.com/questions/57263759/how-can-i-start-the-environment-from-a-custom-initial-state-for-mountain-car"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
