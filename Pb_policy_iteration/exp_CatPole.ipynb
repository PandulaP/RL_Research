{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preference-based Policy Iteration Algorithm\n",
    "\n",
    "This is an attempt to replicate the work done by Fürnkranz et al., (2012) in their paper \"Preference-based reinforcement learning: a formal framework and a policy iteration algorithm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "from IPython.display import HTML\n",
    "import gym\n",
    "from gym import wrappers\n",
    "import io\n",
    "import base64\n",
    "import itertools\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**State observation**:\n",
    "    \n",
    "    Type: Box(4)\n",
    "\n",
    "    Num     Observation               Min                     Max\n",
    "    0       Cart Position             -4.8                    4.8\n",
    "    1       Cart Velocity             -Inf                    Inf\n",
    "    2       Pole Angle                -0.418 rad (-24 deg)    0.418 rad (24 deg)\n",
    "    3       Pole Angular Velocity     -Inf                    Inf\n",
    "\n",
    "- For this project, I will describe the state of the pendulum using only the angle and angular velocity of the pole, ignoring the position and the velocity of cart.\n",
    "\n",
    "**Actions**:\n",
    "\n",
    "    Type: Discrete(2)\n",
    "    \n",
    "    Num   Action\n",
    "    0     Push cart to the left\n",
    "    1     Push cart to the right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of actions: 2\n",
      "Observation space: Box(4,)\n",
      "Max. values of observation space:[4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38]\n",
      "Min. values of observation space:[-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38]\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('CartPole-v0')\n",
    "env.reset()\n",
    "\n",
    "print(\"Number of actions: \" + str(env.action_space.n))\n",
    "print(\"Observation space: \" + str(env.observation_space))\n",
    "print(\"Max. values of observation space:\" + str(env.observation_space.high))\n",
    "print(\"Min. values of observation space:\" + str(env.observation_space.low))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def state_filter(state):\n",
    "    \"\"\" only use the angle and the angular velocity of the pole to describe the state\"\"\"\n",
    "    \n",
    "    return state[[2,3]]\n",
    "\n",
    "\n",
    "def random_action(state):\n",
    "    \"\"\" return a random action: either 0 (left) or 1 (right)\"\"\"\n",
    "    \n",
    "    action = env.action_space.sample()  \n",
    "    return action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I generate random samples $S$ in this setting by simulating a uniform random number (max 100) of uniform random actions from the initial state. If the pendulum fell within this sequence, the procedure was repeated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_init_states_S(seed, filter_state=True):\n",
    "    \"\"\"this function returns a list of randomly generated initial states from the CartPole-v0 environment \"\"\"\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    n_actions = np.random.randint(low=1, high=101)                # how many actions to generate\n",
    "    seq_actions = np.random.randint(low=0,high=2,size=n_actions)  # random sequence of actions\n",
    "\n",
    "    init_states_S = []   # to store initial states\n",
    "\n",
    "    env = gym.make('CartPole-v0')\n",
    "    env.reset()\n",
    "\n",
    "    for action in seq_actions:\n",
    "\n",
    "        state, reward, done, info = env.step(action)  # implement the actions in the random sequence\n",
    "        \n",
    "        if filter_state:\n",
    "            init_states_S.append(state_filter(state)) # append the environment state to list (only angular velocity and angle)\n",
    "        else:\n",
    "            init_states_S.append(state) # all 4 state observations\n",
    "            \n",
    "        if done: # the episode ends either if the pole is > 15 deg from vertical or the cart move by > 2.4 unit from the centre\n",
    "            env.reset()    \n",
    "            \n",
    "    env.close()\n",
    "            \n",
    "    return init_states_S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Generate a sequence of intial states (for $S$) and display first 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "init_states_S = generate_init_states_S(16) # randomly generated states initial\n",
    "\n",
    "env = gym.make('CartPole-v0') # create inv. pend environment\n",
    "env = env.unwrapped           # unwrap the environment to send custom initial states\n",
    "fig = plt.figure(figsize=(20,5))\n",
    "\n",
    "for i in range(10):\n",
    "    env.state = np.concatenate((np.array([0.0,0.0]),init_states_S[i])) # manually adding cart-posi & cart-velocity\n",
    "    fig.add_subplot(2,5,i+1)\n",
    "    plt.imshow(env.render(mode=\"rgb_array\"))\n",
    "    env.close()\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I partition the action space to create multiple actions, because in these cases it becomes less and less likely that a unique best actions can be found. The range of the original action set {0, 1} is partitioned equidistantly into the given number of actions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_action_space(env,n_actions):\n",
    "    \"\"\"this function partitions the action space of a given environment into a given number of `n_actions`\"\"\"\n",
    "    \n",
    "    actions = np.arange(env.action_space.n)\n",
    "\n",
    "    # a uniform noise term is added to action signals to make all state transitions non-deterministic\n",
    "    part_act_space = np.linspace(actions[0],actions[-1],n_actions) + np.random.uniform(low = -.2,high=.2) \n",
    "    \n",
    "    return part_act_space                                                                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original action space: 2\n",
      "Partitioned into 3 actions: [-0.12215384  0.37784616  0.87784616]\n",
      "Partitioned into 9 actions: [-0.09014737  0.03485263  0.15985263  0.28485263  0.40985263  0.53485263\n",
      "  0.65985263  0.78485263  0.90985263]\n",
      "Partitioned into 17 actions: [-0.14760155 -0.08510155 -0.02260155  0.03989845  0.10239845  0.16489845\n",
      "  0.22739845  0.28989845  0.35239845  0.41489845  0.47739845  0.53989845\n",
      "  0.60239845  0.66489845  0.72739845  0.78989845  0.85239845]\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('CartPole-v0')\n",
    "\n",
    "print(\"Original action space: \" + str(env.action_space.n))\n",
    "print(\"Partitioned into 3 actions: \" + str(partition_action_space(env,3)))\n",
    "print(\"Partitioned into 9 actions: \" + str(partition_action_space(env,9)))\n",
    "print(\"Partitioned into 17 actions: \" + str(partition_action_space(env,17)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preference-based Approximate Policy Iteration algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "### Evaluate-Preference procedure ###\n",
    "\n",
    "### Description:\n",
    "###  This is done using roll-outs\n",
    "###  At every state in the initial state set, roll-outs are generated from each action for the same policy\n",
    "###  Accumulated rewards from each roll-out from each action are used to generate preferences for every pair of actions\n",
    "###  Generated preferences are stored in the training set; training data are used to learn the LabelRanker\n",
    "\n",
    "### Functionality:\n",
    "### - INPUTS  : starting state (s), two-actions(a_k, a_j), (current) policy (\\pi), max. length of trajectoris (L)\n",
    "### - PROCESS : generate roll-out (fixed time horizon) and calculate accumulate reward\n",
    "### - OUTPUT  : compare return from each rollout: store preference info in training dataset as (s,a_k > a_j)\n",
    "\n",
    "### - Run this procedure for every action-pair at all initial-states\n",
    "\n",
    "def evaluate_preference(starting_state\n",
    "                        , action_1\n",
    "                        , action_2\n",
    "                        , policy\n",
    "                        , environment_name = 'CartPole-v0'\n",
    "                        , discount_fac = 0.99\n",
    "                        , n_rollouts = 10\n",
    "                        , max_rollout_len = 10\n",
    "                       ):\n",
    "    \n",
    "    policy = policy              # policy to follow in roll-outs\n",
    "    n_rollouts = n_rollouts      # number of roll-outs to generate\n",
    "    gamma = discount_fac         # discount factor\n",
    "\n",
    "    # state is 4 dimensional by default: if only 2 give, has to expand to 4 dimensions\n",
    "    if len(starting_state) == 2:\n",
    "        # manually define state-values for 'cart-position' & 'cart-velocity'\n",
    "        cart_posi, cart_velo = 0,0   \n",
    "        s_init = np.concatenate((np.array([cart_posi,cart_velo]),starting_state))\n",
    "    else:\n",
    "        s_init = starting_state\n",
    "        \n",
    "    # dict. to store actions\n",
    "    actions = { 'one' : action_1 \n",
    "              , 'two' : action_2}    \n",
    "\n",
    "    # dict to store  rewards of roll-outs starting from each action\n",
    "    r = { 'one' : [None]*n_rollouts \n",
    "        , 'two' : [None]*n_rollouts}  \n",
    "\n",
    "    # dict to store average discounted return for for each action\n",
    "    avg_r = {}  \n",
    "\n",
    "    max_traj_len = max_rollout_len # maximum roll-out trajectory length\n",
    "\n",
    "    for action_key, action_value in actions.items():\n",
    "\n",
    "        # generate roll-outs\n",
    "        for rollout in range(n_rollouts):\n",
    "\n",
    "            env = gym.make(environment_name)\n",
    "            env = env.unwrapped\n",
    "\n",
    "            env.state = s_init  # set the starting state\n",
    "\n",
    "            # absolute of the rounded action value is applied in case action space is partitioned\n",
    "            #print(abs(round(action_value)))\n",
    "            observation, reward, done, info = env.step(int(abs(round(action_value))))\n",
    "\n",
    "            r[action_key][rollout] = reward # add the immediate reward of the action\n",
    "\n",
    "            traj_len = 1\n",
    "            while traj_len < max_traj_len and not done:\n",
    "\n",
    "                observation, reward, done, info = env.step(policy(observation)) ### NEED TO DEFINE A POLICY\n",
    "\n",
    "                r[action_key][rollout] += (gamma**traj_len) * reward\n",
    "\n",
    "                traj_len += 1\n",
    "\n",
    "            env.reset()\n",
    "            env.close()\n",
    "\n",
    "        # calculate average discounted return \n",
    "        avg_r[action_key]  = sum(r[action_key]) / len(r[action_key])\n",
    "\n",
    "    # return preference info. to generate training data\n",
    "    if avg_r['one'] > avg_r['two']:\n",
    "        return {'state': s_init[[2,3]] if len(s_init)>2 else s_init # only use the angel and velocity of pendulum for state\n",
    "               , 'a_j' : actions['one']\n",
    "               , 'a_k' : actions['two']\n",
    "               , 'preference_label' : 1}\n",
    "#     elif avg_r['two'] > avg_r['one']:\n",
    "#         return {'state': s_init[[2,3]] if len(s_init)>2 else s_init  # only use the angel and velocity of pendulum for state\n",
    "#                , 'a_k_prefered_a_j' : [actions['two'],actions['one']]\n",
    "#                , 'preference_label' : 1}\n",
    "    else:\n",
    "        return {'state': s_init[[2,3]] if len(s_init)>2 else s_init # only use the angel and velocity of pendulum for state\n",
    "               , 'a_j' : actions['one']\n",
    "               , 'a_k' : actions['two']\n",
    "               , 'preference_label' : 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': array([0.04932088, 0.04057652]),\n",
       " 'a_j': 0.3,\n",
       " 'a_k': 0.6,\n",
       " 'preference_label': 0}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_preference(env.reset(),0.3,0.6,random_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.56s/it]\n"
     ]
    }
   ],
   "source": [
    "###################################################\n",
    "### Preference-Based Policy Iteration Algorithm ###\n",
    "\n",
    "### Functionality:\n",
    "### - INPUTS  : sample states (s'), initial (random) policy (\\pi0), max. num. of policy iterations (p)\n",
    "### - PROCESS : generate roll-out (fixed time horizon) and calculate accumulate reward\n",
    "### - OUTPUT  : compare return from each rollout: store preference info in training dataset as (s,a_k > a_j)\n",
    "\n",
    "\n",
    "# initialize environment\n",
    "env = gym.make('CartPole-v0')\n",
    "\n",
    "# initial random policy\n",
    "policy_init = random_action\n",
    "policy = policy_init\n",
    "\n",
    "# sample states\n",
    "sample_states = generate_init_states_S(seed = 16) # randomly generated states initial\n",
    "\n",
    "# maximum number of policy iterations\n",
    "max_iterr = 1 # increase this after writing the LabelRanker\n",
    "\n",
    "# action space to consider\n",
    "act_space = partition_action_space(env,3)\n",
    "\n",
    "# generate action-pairs (per each)\n",
    "act_pairs = list(itertools.combinations(act_space,2))\n",
    "\n",
    "# place-holder for training data\n",
    "train_data = []\n",
    "\n",
    "iterr = 0\n",
    "\n",
    "pbar = tqdm.tqdm(total=max_iterr)\n",
    "\n",
    "while iterr < max_iterr:\n",
    "    \n",
    "    # place-holder for training data\n",
    "    #train_data = [] # uncomment this after adding LabelRanker\n",
    "\n",
    "    \n",
    "    for state in sample_states:\n",
    "        \n",
    "        for action_pair in act_pairs:\n",
    "            preference_out = evaluate_preference(state, action_pair[0], action_pair[1], policy)\n",
    "            \n",
    "            if preference_out is not None:\n",
    "                train_data.append(preference_out)\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "    pbar.update(1)\n",
    "    iterr += 1\n",
    "    \n",
    "    \n",
    "pbar.close()\n",
    "\n",
    "### Train LaberRanker using train-data\n",
    "### Create new policy using LabeRanker\n",
    "### Re-run loop with new policy\n",
    "\n",
    "        \n",
    "        \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `LABEL-RANKER` Model training Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>a_j</th>\n",
       "      <th>a_k</th>\n",
       "      <th>preference_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[-0.04042570338131652, 0.2768141014688637]</td>\n",
       "      <td>-0.122154</td>\n",
       "      <td>0.377846</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[-0.04042570338131652, 0.2768141014688637]</td>\n",
       "      <td>-0.122154</td>\n",
       "      <td>0.877846</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[-0.04042570338131652, 0.2768141014688637]</td>\n",
       "      <td>0.377846</td>\n",
       "      <td>0.877846</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        state       a_j       a_k  \\\n",
       "0  [-0.04042570338131652, 0.2768141014688637] -0.122154  0.377846   \n",
       "1  [-0.04042570338131652, 0.2768141014688637] -0.122154  0.877846   \n",
       "2  [-0.04042570338131652, 0.2768141014688637]  0.377846  0.877846   \n",
       "\n",
       "   preference_label  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 0  "
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a key for state\n",
    "train_df.loc[:, 'state_key'] = train_df.state.apply(lambda x: x[0].astype(str)+\"_\"+x[1].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all states which does not have any preferred action\n",
    "temp_df1 = train_df.groupby('state_key').preference_label.sum().reset_index()\n",
    "temp_df1 = temp_df1.loc[temp_df1.preference_label>0] # pick the states that have at least one prefered action\n",
    "train_df = train_df.merge(right = temp_df1.loc[:,'state_key']\n",
    "                          , right_on = 'state_key'\n",
    "                          , left_on = 'state_key'\n",
    "                          , how = 'right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a single column with the set of actions executed per state\n",
    "temp_df1 = train_df.groupby('state_key')['a_j'].unique().reset_index()\n",
    "temp_df2 = train_df.groupby('state_key')['a_k'].unique().reset_index()\n",
    "temp_df3 = temp_df1.merge(right=temp_df2\n",
    "                          , right_on = 'state_key'\n",
    "                          , left_on = 'state_key'\n",
    "                          , how = 'inner')\n",
    "temp_df3.loc[:,'unique_acts'] = temp_df3.apply(lambda row: set(list(row['a_j']) + list(row['a_k'])) ,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_key</th>\n",
       "      <th>a_j</th>\n",
       "      <th>a_k</th>\n",
       "      <th>unique_acts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.007119426465262891_0.010133984961571807</td>\n",
       "      <td>[-0.12215383778081441, 0.3778461622191856]</td>\n",
       "      <td>[0.3778461622191856, 0.8778461622191855]</td>\n",
       "      <td>{-0.12215383778081441, 0.8778461622191855, 0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.035456221985432065_-0.331823583123806</td>\n",
       "      <td>[-0.12215383778081441, 0.3778461622191856]</td>\n",
       "      <td>[0.3778461622191856, 0.8778461622191855]</td>\n",
       "      <td>{-0.12215383778081441, 0.8778461622191855, 0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.042092693647908186_-0.635473455421564</td>\n",
       "      <td>[-0.12215383778081441, 0.3778461622191856]</td>\n",
       "      <td>[0.3778461622191856, 0.8778461622191855]</td>\n",
       "      <td>{-0.12215383778081441, 0.8778461622191855, 0.3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    state_key  \\\n",
       "0  -0.007119426465262891_0.010133984961571807   \n",
       "1    -0.035456221985432065_-0.331823583123806   \n",
       "2    -0.042092693647908186_-0.635473455421564   \n",
       "\n",
       "                                          a_j  \\\n",
       "0  [-0.12215383778081441, 0.3778461622191856]   \n",
       "1  [-0.12215383778081441, 0.3778461622191856]   \n",
       "2  [-0.12215383778081441, 0.3778461622191856]   \n",
       "\n",
       "                                        a_k  \\\n",
       "0  [0.3778461622191856, 0.8778461622191855]   \n",
       "1  [0.3778461622191856, 0.8778461622191855]   \n",
       "2  [0.3778461622191856, 0.8778461622191855]   \n",
       "\n",
       "                                         unique_acts  \n",
       "0  {-0.12215383778081441, 0.8778461622191855, 0.3...  \n",
       "1  {-0.12215383778081441, 0.8778461622191855, 0.3...  \n",
       "2  {-0.12215383778081441, 0.8778461622191855, 0.3...  "
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df3.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the unique-action column to train dataset\n",
    "train_df = train_df.merge(right = temp_df3.loc[:,['state_key', 'unique_acts']]\n",
    "              , right_on =  'state_key'\n",
    "              , left_on = 'state_key'\n",
    "              , how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>a_j</th>\n",
       "      <th>a_k</th>\n",
       "      <th>preference_label</th>\n",
       "      <th>state_key</th>\n",
       "      <th>unique_acts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>[-0.054802162756339465, -0.9411095238977125]</td>\n",
       "      <td>-0.122154</td>\n",
       "      <td>0.377846</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.054802162756339465_-0.9411095238977125</td>\n",
       "      <td>{-0.12215383778081441, 0.8778461622191855, 0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>[-0.054802162756339465, -0.9411095238977125]</td>\n",
       "      <td>-0.122154</td>\n",
       "      <td>0.877846</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.054802162756339465_-0.9411095238977125</td>\n",
       "      <td>{-0.12215383778081441, 0.8778461622191855, 0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>[-0.054802162756339465, -0.9411095238977125]</td>\n",
       "      <td>0.377846</td>\n",
       "      <td>0.877846</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.054802162756339465_-0.9411095238977125</td>\n",
       "      <td>{-0.12215383778081441, 0.8778461622191855, 0.3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          state       a_j       a_k  \\\n",
       "6  [-0.054802162756339465, -0.9411095238977125] -0.122154  0.377846   \n",
       "7  [-0.054802162756339465, -0.9411095238977125] -0.122154  0.877846   \n",
       "8  [-0.054802162756339465, -0.9411095238977125]  0.377846  0.877846   \n",
       "\n",
       "   preference_label                                  state_key  \\\n",
       "6                 1  -0.054802162756339465_-0.9411095238977125   \n",
       "7                 1  -0.054802162756339465_-0.9411095238977125   \n",
       "8                 1  -0.054802162756339465_-0.9411095238977125   \n",
       "\n",
       "                                         unique_acts  \n",
       "6  {-0.12215383778081441, 0.8778461622191855, 0.3...  \n",
       "7  {-0.12215383778081441, 0.8778461622191855, 0.3...  \n",
       "8  {-0.12215383778081441, 0.8778461622191855, 0.3...  "
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.loc[train_df.state_key == '-0.054802162756339465_-0.9411095238977125']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a 'prefered-action' value for each state\n",
    "train_df.loc[:,'prefered_action'] = train_df.apply(lambda row: row['a_j'] if row['preference_label'] == 1 else row['a_k']  ,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>a_j</th>\n",
       "      <th>a_k</th>\n",
       "      <th>preference_label</th>\n",
       "      <th>state_key</th>\n",
       "      <th>unique_acts</th>\n",
       "      <th>prefered_action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[-0.035456221985432065, -0.331823583123806]</td>\n",
       "      <td>-0.122154</td>\n",
       "      <td>0.377846</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.035456221985432065_-0.331823583123806</td>\n",
       "      <td>{-0.12215383778081441, 0.8778461622191855, 0.3...</td>\n",
       "      <td>0.377846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[-0.035456221985432065, -0.331823583123806]</td>\n",
       "      <td>-0.122154</td>\n",
       "      <td>0.877846</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.035456221985432065_-0.331823583123806</td>\n",
       "      <td>{-0.12215383778081441, 0.8778461622191855, 0.3...</td>\n",
       "      <td>-0.122154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[-0.035456221985432065, -0.331823583123806]</td>\n",
       "      <td>0.377846</td>\n",
       "      <td>0.877846</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.035456221985432065_-0.331823583123806</td>\n",
       "      <td>{-0.12215383778081441, 0.8778461622191855, 0.3...</td>\n",
       "      <td>0.377846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[-0.042092693647908186, -0.635473455421564]</td>\n",
       "      <td>-0.122154</td>\n",
       "      <td>0.377846</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.042092693647908186_-0.635473455421564</td>\n",
       "      <td>{-0.12215383778081441, 0.8778461622191855, 0.3...</td>\n",
       "      <td>0.377846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[-0.042092693647908186, -0.635473455421564]</td>\n",
       "      <td>-0.122154</td>\n",
       "      <td>0.877846</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.042092693647908186_-0.635473455421564</td>\n",
       "      <td>{-0.12215383778081441, 0.8778461622191855, 0.3...</td>\n",
       "      <td>-0.122154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         state       a_j       a_k  \\\n",
       "0  [-0.035456221985432065, -0.331823583123806] -0.122154  0.377846   \n",
       "1  [-0.035456221985432065, -0.331823583123806] -0.122154  0.877846   \n",
       "2  [-0.035456221985432065, -0.331823583123806]  0.377846  0.877846   \n",
       "3  [-0.042092693647908186, -0.635473455421564] -0.122154  0.377846   \n",
       "4  [-0.042092693647908186, -0.635473455421564] -0.122154  0.877846   \n",
       "\n",
       "   preference_label                                 state_key  \\\n",
       "0                 0  -0.035456221985432065_-0.331823583123806   \n",
       "1                 1  -0.035456221985432065_-0.331823583123806   \n",
       "2                 1  -0.035456221985432065_-0.331823583123806   \n",
       "3                 0  -0.042092693647908186_-0.635473455421564   \n",
       "4                 1  -0.042092693647908186_-0.635473455421564   \n",
       "\n",
       "                                         unique_acts  prefered_action  \n",
       "0  {-0.12215383778081441, 0.8778461622191855, 0.3...         0.377846  \n",
       "1  {-0.12215383778081441, 0.8778461622191855, 0.3...        -0.122154  \n",
       "2  {-0.12215383778081441, 0.8778461622191855, 0.3...         0.377846  \n",
       "3  {-0.12215383778081441, 0.8778461622191855, 0.3...         0.377846  \n",
       "4  {-0.12215383778081441, 0.8778461622191855, 0.3...        -0.122154  "
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>prefered_action</th>\n",
       "      <th>-0.122154</th>\n",
       "      <th>0.377846</th>\n",
       "      <th>0.877846</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state_key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>-0.007119426465262891_0.010133984961571807</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>-0.035456221985432065_-0.331823583123806</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>-0.042092693647908186_-0.635473455421564</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>-0.054802162756339465_-0.9411095238977125</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>-0.07362435323429371_-0.6661375648946086</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "prefered_action                             -0.122154   0.377846   0.877846\n",
       "state_key                                                                  \n",
       "-0.007119426465262891_0.010133984961571807        1.0        1.0        1.0\n",
       "-0.035456221985432065_-0.331823583123806          1.0        2.0        0.0\n",
       "-0.042092693647908186_-0.635473455421564          1.0        2.0        0.0\n",
       "-0.054802162756339465_-0.9411095238977125         2.0        1.0        0.0\n",
       "-0.07362435323429371_-0.6661375648946086          2.0        1.0        0.0"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_preference_counts = train_df.groupby('state_key').prefered_action.value_counts().unstack()\n",
    "action_preference_counts.replace(np.nan,0,inplace=True)\n",
    "action_preference_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "### create training labels for each state\n",
    "action_preference_counts.loc[:, 'preference_label_vector'] = action_preference_counts.iloc[:,0:].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>prefered_action</th>\n",
       "      <th>-0.12215383778081441</th>\n",
       "      <th>0.3778461622191856</th>\n",
       "      <th>0.8778461622191855</th>\n",
       "      <th>preference_label_vector</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state_key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>-0.007119426465262891_0.010133984961571807</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1.0, 1.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>-0.035456221985432065_-0.331823583123806</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[1.0, 2.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>-0.042092693647908186_-0.635473455421564</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[1.0, 2.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>-0.054802162756339465_-0.9411095238977125</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[2.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>-0.07362435323429371_-0.6661375648946086</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[2.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "prefered_action                             -0.12215383778081441  \\\n",
       "state_key                                                          \n",
       "-0.007119426465262891_0.010133984961571807                   1.0   \n",
       "-0.035456221985432065_-0.331823583123806                     1.0   \n",
       "-0.042092693647908186_-0.635473455421564                     1.0   \n",
       "-0.054802162756339465_-0.9411095238977125                    2.0   \n",
       "-0.07362435323429371_-0.6661375648946086                     2.0   \n",
       "\n",
       "prefered_action                             0.3778461622191856  \\\n",
       "state_key                                                        \n",
       "-0.007119426465262891_0.010133984961571807                 1.0   \n",
       "-0.035456221985432065_-0.331823583123806                   2.0   \n",
       "-0.042092693647908186_-0.635473455421564                   2.0   \n",
       "-0.054802162756339465_-0.9411095238977125                  1.0   \n",
       "-0.07362435323429371_-0.6661375648946086                   1.0   \n",
       "\n",
       "prefered_action                             0.8778461622191855  \\\n",
       "state_key                                                        \n",
       "-0.007119426465262891_0.010133984961571807                 1.0   \n",
       "-0.035456221985432065_-0.331823583123806                   0.0   \n",
       "-0.042092693647908186_-0.635473455421564                   0.0   \n",
       "-0.054802162756339465_-0.9411095238977125                  0.0   \n",
       "-0.07362435323429371_-0.6661375648946086                   0.0   \n",
       "\n",
       "prefered_action                            preference_label_vector  \n",
       "state_key                                                           \n",
       "-0.007119426465262891_0.010133984961571807         [1.0, 1.0, 1.0]  \n",
       "-0.035456221985432065_-0.331823583123806           [1.0, 2.0, 0.0]  \n",
       "-0.042092693647908186_-0.635473455421564           [1.0, 2.0, 0.0]  \n",
       "-0.054802162756339465_-0.9411095238977125          [2.0, 1.0, 0.0]  \n",
       "-0.07362435323429371_-0.6661375648946086           [2.0, 1.0, 0.0]  "
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_preference_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add preference label data to training dataset\n",
    "train_df = train_df.merge(right = action_preference_counts.loc[:,['preference_label_vector']]\n",
    "                          , right_index= True\n",
    "                          , left_on = 'state_key'\n",
    "                          , how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the reduced training dataset\n",
    "train_df_reduced = train_df.loc[:,['state', 'state_key', 'unique_acts', 'preference_label_vector']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>state_key</th>\n",
       "      <th>unique_acts</th>\n",
       "      <th>preference_label_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[-0.035456221985432065, -0.331823583123806]</td>\n",
       "      <td>-0.035456221985432065_-0.331823583123806</td>\n",
       "      <td>{-0.12215383778081441, 0.8778461622191855, 0.3...</td>\n",
       "      <td>[1.0, 2.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[-0.042092693647908186, -0.635473455421564]</td>\n",
       "      <td>-0.042092693647908186_-0.635473455421564</td>\n",
       "      <td>{-0.12215383778081441, 0.8778461622191855, 0.3...</td>\n",
       "      <td>[1.0, 2.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>[-0.054802162756339465, -0.9411095238977125]</td>\n",
       "      <td>-0.054802162756339465_-0.9411095238977125</td>\n",
       "      <td>{-0.12215383778081441, 0.8778461622191855, 0.3...</td>\n",
       "      <td>[2.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>[-0.07362435323429371, -0.6661375648946086]</td>\n",
       "      <td>-0.07362435323429371_-0.6661375648946086</td>\n",
       "      <td>{-0.12215383778081441, 0.8778461622191855, 0.3...</td>\n",
       "      <td>[2.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>[-0.08694710453218589, -0.9810636811130726]</td>\n",
       "      <td>-0.08694710453218589_-0.9810636811130726</td>\n",
       "      <td>{-0.12215383778081441, 0.8778461622191855, 0.3...</td>\n",
       "      <td>[1.0, 2.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>[-0.10656837815444734, -1.29974162808073]</td>\n",
       "      <td>-0.10656837815444734_-1.29974162808073</td>\n",
       "      <td>{-0.12215383778081441, 0.8778461622191855, 0.3...</td>\n",
       "      <td>[1.0, 2.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>[-0.13256321071606192, -1.0422308309883974]</td>\n",
       "      <td>-0.13256321071606192_-1.0422308309883974</td>\n",
       "      <td>{-0.12215383778081441, 0.8778461622191855, 0.3...</td>\n",
       "      <td>[2.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>[-0.15340782733582986, -1.373417153619405]</td>\n",
       "      <td>-0.15340782733582986_-1.373417153619405</td>\n",
       "      <td>{-0.12215383778081441, 0.8778461622191855, 0.3...</td>\n",
       "      <td>[1.0, 2.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>[0.04629876102299209, 1.1981952421426543]</td>\n",
       "      <td>0.04629876102299209_1.1981952421426543</td>\n",
       "      <td>{-0.12215383778081441, 0.8778461622191855, 0.3...</td>\n",
       "      <td>[1.0, 0.0, 2.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>[0.07026266586584518, 1.5050219120869652]</td>\n",
       "      <td>0.07026266586584518_1.5050219120869652</td>\n",
       "      <td>{-0.12215383778081441, 0.8778461622191855, 0.3...</td>\n",
       "      <td>[1.0, 0.0, 2.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>[0.04233885154470975, 0.5989202808300356]</td>\n",
       "      <td>0.04233885154470975_0.5989202808300356</td>\n",
       "      <td>{-0.12215383778081441, 0.8778461622191855, 0.3...</td>\n",
       "      <td>[1.0, 0.0, 2.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>[0.061610580793693366, 0.3560017859350264]</td>\n",
       "      <td>0.061610580793693366_0.3560017859350264</td>\n",
       "      <td>{-0.12215383778081441, 0.8778461622191855, 0.3...</td>\n",
       "      <td>[1.0, 0.0, 2.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>[0.07039791650761998, 0.3969162694946521]</td>\n",
       "      <td>0.07039791650761998_0.3969162694946521</td>\n",
       "      <td>{-0.12215383778081441, 0.8778461622191855, 0.3...</td>\n",
       "      <td>[1.0, 0.0, 2.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>[0.15021835166057254, 0.8411925593620657]</td>\n",
       "      <td>0.15021835166057254_0.8411925593620657</td>\n",
       "      <td>{-0.12215383778081441, 0.8778461622191855, 0.3...</td>\n",
       "      <td>[1.0, 0.0, 2.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>[0.003955319880723901, -0.28279130622413773]</td>\n",
       "      <td>0.003955319880723901_-0.28279130622413773</td>\n",
       "      <td>{-0.12215383778081441, 0.8778461622191855, 0.3...</td>\n",
       "      <td>[0.0, 2.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>[-0.007119426465262891, 0.010133984961571807]</td>\n",
       "      <td>-0.007119426465262891_0.010133984961571807</td>\n",
       "      <td>{-0.12215383778081441, 0.8778461622191855, 0.3...</td>\n",
       "      <td>[1.0, 1.0, 1.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            state  \\\n",
       "0     [-0.035456221985432065, -0.331823583123806]   \n",
       "3     [-0.042092693647908186, -0.635473455421564]   \n",
       "6    [-0.054802162756339465, -0.9411095238977125]   \n",
       "9     [-0.07362435323429371, -0.6661375648946086]   \n",
       "12    [-0.08694710453218589, -0.9810636811130726]   \n",
       "15      [-0.10656837815444734, -1.29974162808073]   \n",
       "18    [-0.13256321071606192, -1.0422308309883974]   \n",
       "21     [-0.15340782733582986, -1.373417153619405]   \n",
       "24      [0.04629876102299209, 1.1981952421426543]   \n",
       "27      [0.07026266586584518, 1.5050219120869652]   \n",
       "30      [0.04233885154470975, 0.5989202808300356]   \n",
       "33     [0.061610580793693366, 0.3560017859350264]   \n",
       "36      [0.07039791650761998, 0.3969162694946521]   \n",
       "39      [0.15021835166057254, 0.8411925593620657]   \n",
       "42   [0.003955319880723901, -0.28279130622413773]   \n",
       "45  [-0.007119426465262891, 0.010133984961571807]   \n",
       "\n",
       "                                     state_key  \\\n",
       "0     -0.035456221985432065_-0.331823583123806   \n",
       "3     -0.042092693647908186_-0.635473455421564   \n",
       "6    -0.054802162756339465_-0.9411095238977125   \n",
       "9     -0.07362435323429371_-0.6661375648946086   \n",
       "12    -0.08694710453218589_-0.9810636811130726   \n",
       "15      -0.10656837815444734_-1.29974162808073   \n",
       "18    -0.13256321071606192_-1.0422308309883974   \n",
       "21     -0.15340782733582986_-1.373417153619405   \n",
       "24      0.04629876102299209_1.1981952421426543   \n",
       "27      0.07026266586584518_1.5050219120869652   \n",
       "30      0.04233885154470975_0.5989202808300356   \n",
       "33     0.061610580793693366_0.3560017859350264   \n",
       "36      0.07039791650761998_0.3969162694946521   \n",
       "39      0.15021835166057254_0.8411925593620657   \n",
       "42   0.003955319880723901_-0.28279130622413773   \n",
       "45  -0.007119426465262891_0.010133984961571807   \n",
       "\n",
       "                                          unique_acts preference_label_vector  \n",
       "0   {-0.12215383778081441, 0.8778461622191855, 0.3...         [1.0, 2.0, 0.0]  \n",
       "3   {-0.12215383778081441, 0.8778461622191855, 0.3...         [1.0, 2.0, 0.0]  \n",
       "6   {-0.12215383778081441, 0.8778461622191855, 0.3...         [2.0, 1.0, 0.0]  \n",
       "9   {-0.12215383778081441, 0.8778461622191855, 0.3...         [2.0, 1.0, 0.0]  \n",
       "12  {-0.12215383778081441, 0.8778461622191855, 0.3...         [1.0, 2.0, 0.0]  \n",
       "15  {-0.12215383778081441, 0.8778461622191855, 0.3...         [1.0, 2.0, 0.0]  \n",
       "18  {-0.12215383778081441, 0.8778461622191855, 0.3...         [2.0, 1.0, 0.0]  \n",
       "21  {-0.12215383778081441, 0.8778461622191855, 0.3...         [1.0, 2.0, 0.0]  \n",
       "24  {-0.12215383778081441, 0.8778461622191855, 0.3...         [1.0, 0.0, 2.0]  \n",
       "27  {-0.12215383778081441, 0.8778461622191855, 0.3...         [1.0, 0.0, 2.0]  \n",
       "30  {-0.12215383778081441, 0.8778461622191855, 0.3...         [1.0, 0.0, 2.0]  \n",
       "33  {-0.12215383778081441, 0.8778461622191855, 0.3...         [1.0, 0.0, 2.0]  \n",
       "36  {-0.12215383778081441, 0.8778461622191855, 0.3...         [1.0, 0.0, 2.0]  \n",
       "39  {-0.12215383778081441, 0.8778461622191855, 0.3...         [1.0, 0.0, 2.0]  \n",
       "42  {-0.12215383778081441, 0.8778461622191855, 0.3...         [0.0, 2.0, 1.0]  \n",
       "45  {-0.12215383778081441, 0.8778461622191855, 0.3...         [1.0, 1.0, 1.0]  "
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_reduced.drop_duplicates(subset=['state_key'],inplace=True)\n",
    "train_df_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# above dataset has - state + list of actions + # preferences made for each action (at state) --> each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_out_labels = torch.tensor(train_df.preference_label.values.tolist())\n",
    "#train_out_labels =[ torch.tensor(label) for label in train_df.preference_label.values.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self, num_numerical_cols, output_size, layers, p=0.4):\n",
    "        super().__init__()\n",
    "        self.batch_norm_num = nn.BatchNorm1d(num_numerical_cols)\n",
    "\n",
    "        all_layers = []\n",
    "        input_size = num_numerical_cols\n",
    "\n",
    "        for i in layers:\n",
    "            all_layers.append(nn.Linear(input_size, i))\n",
    "            all_layers.append(nn.ReLU(inplace=True))\n",
    "            all_layers.append(nn.BatchNorm1d(i))\n",
    "            all_layers.append(nn.Dropout(p))\n",
    "            input_size = i\n",
    "\n",
    "        all_layers.append(nn.Linear(layers[-1], output_size))\n",
    "\n",
    "        self.layers = nn.Sequential(*all_layers)\n",
    "\n",
    "    def forward(self, x_numerical):\n",
    "        x_numerical = self.batch_norm_num(x_numerical)\n",
    "        x = self.layers(x_numerical)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(train_samples.shape[1], 2, [200,100,50], p=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (batch_norm_num): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=4, out_features=200, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.4, inplace=False)\n",
      "    (4): Linear(in_features=200, out_features=100, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): Dropout(p=0.4, inplace=False)\n",
      "    (8): Linear(in_features=100, out_features=50, bias=True)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): Dropout(p=0.4, inplace=False)\n",
      "    (12): Linear(in_features=50, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   1 loss: 0.86207616\n",
      "epoch:  26 loss: 0.39926690\n",
      "epoch:  51 loss: 0.33612713\n",
      "epoch:  76 loss: 0.31516284\n",
      "epoch: 101 loss: 0.30613711\n",
      "epoch: 126 loss: 0.29426527\n",
      "epoch: 151 loss: 0.28912571\n",
      "epoch: 176 loss: 0.27681562\n",
      "epoch: 201 loss: 0.28387845\n",
      "epoch: 226 loss: 0.28130651\n",
      "epoch: 251 loss: 0.27547008\n",
      "epoch: 276 loss: 0.27505055\n",
      "epoch: 300 loss: 0.2682622969\n"
     ]
    }
   ],
   "source": [
    "epochs = 300\n",
    "aggregated_losses = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    i += 1\n",
    "    y_pred = model(train_samples.float())\n",
    "    single_loss = loss_function(y_pred, train_out_labels)\n",
    "    aggregated_losses.append(single_loss)\n",
    "\n",
    "    if i%25 == 1:\n",
    "        print(f'epoch: {i:3} loss: {single_loss.item():10.8f}')\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    single_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(f'epoch: {i:3} loss: {single_loss.item():10.10f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(epochs), aggregated_losses)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('epoch');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Label Ranker ###\n",
    "\n",
    "# To-be completed after creating a training-dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.00736531, 0.26078459])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_posi, c_velo = 0,0 # manually define state-values for 'cart-position' & 'cart-velocity'\n",
    "np.concatenate((np.array([c_posi,c_velo]),sample_states[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v0')\n",
    "c_posi, c_velo = 0,0 # manually define state-values for 'cart-position' & 'cart-velocity'\n",
    "env = env.unwrapped\n",
    "env = wrappers.Monitor(env, \"./gym-results\", force=True)\n",
    "env.reset()\n",
    "env.state = np.concatenate((np.array([c_posi,c_velo]),sample_states[0]))\n",
    "for _ in range(100):\n",
    "    action = env.action_space.sample()\n",
    "    observation, reward, done, info = env.step(action)\n",
    "    if done: break\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <video width=\"360\" height=\"auto\" alt=\"test\" controls><source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" /></video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video = io.open('./gym-results/openaigym.video.%s.video000000.mp4' % env.file_infix, 'r+b').read()\n",
    "encoded = base64.b64encode(video)\n",
    "HTML(data='''\n",
    "    <video width=\"360\" height=\"auto\" alt=\"test\" controls><source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" /></video>'''\n",
    ".format(encoded.decode('ascii')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APPENDIX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <video width=\"360\" height=\"auto\" alt=\"test\" controls><source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" /></video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make('CartPole-v0')\n",
    "env = wrappers.Monitor(env, \"./gym-results\", force=True)\n",
    "env.reset()\n",
    "for _ in range(1000):\n",
    "    action = env.action_space.sample()\n",
    "    observation, reward, done, info = env.step(action)\n",
    "    if done: break\n",
    "env.close()\n",
    "\n",
    "video = io.open('./gym-results/openaigym.video.%s.video000000.mp4' % env.file_infix, 'r+b').read()\n",
    "encoded = base64.b64encode(video)\n",
    "HTML(data='''\n",
    "    <video width=\"360\" height=\"auto\" alt=\"test\" controls><source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" /></video>'''\n",
    ".format(encoded.decode('ascii')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 19 finished after 8 timesteps. Total reward: 8.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAARt0lEQVR4nO3dcazdZ33f8fdnTgisoCYhN5FnO3PauirpNBx2F1xlf6SBtiGqairBlGwqFopkJgUJJLQt6aQVpEVqpZVUaFuEq2SYiRLSAooVZaOeCar4g4QbMMbGpDFgkVtb8WUkAYSWLeG7P85zyZlz7Ht87z2597nn/ZKOfr/f83t+53wf5eTj333uc+5JVSFJ6sffW+sCJEkXxuCWpM4Y3JLUGYNbkjpjcEtSZwxuSerMxII7yc1JnkxyIsmdk3odSZo2mcQ67iSbgL8FfguYB74K3FZV31r1F5OkKTOpO+7rgRNV9d2q+j/AA8DuCb2WJE2Viyb0vFuAp4eO54G3nqvzFVdcUdu3b59QKZLUn5MnT/KDH/wgo85NKrhHvdj/NyeTZC+wF+Dqq69mbm5uQqVIUn9mZ2fPeW5SUyXzwLah463AqeEOVbWvqmaranZmZmZCZUjSxjOp4P4qsCPJNUleA9wKHJjQa0nSVJnIVElVvZjk/cAXgE3A/VV1bBKvJUnTZlJz3FTVI8Ajk3p+SZpWfnJSkjpjcEtSZwxuSeqMwS1JnTG4JakzBrckdcbglqTOGNyS1BmDW5I6Y3BLUmcMbknqjMEtSZ0xuCWpMwa3JHXG4JakzhjcktQZg1uSOmNwS1JnVvTVZUlOAj8GXgJerKrZJJcDnwG2AyeBf15Vz66sTEnSotW44/7NqtpZVbPt+E7gUFXtAA61Y0nSKpnEVMluYH/b3w+8cwKvIUlTa6XBXcBfJ3kiyd7WdlVVnQZo2ytX+BqSpCErmuMGbqiqU0muBA4m+fa4F7ag3wtw9dVXr7AMSZoeK7rjrqpTbXsG+DxwPfBMks0AbXvmHNfuq6rZqpqdmZlZSRmSNFWWHdxJfiHJGxb3gd8GjgIHgD2t2x7goZUWKUl62UqmSq4CPp9k8Xn+oqr+R5KvAg8muR34PvDulZcpSVq07OCuqu8Cbx7R/r+At62kKEnSufnJSUnqjMEtSZ0xuCWpMwa3JHXG4JakzhjcktQZg1uSOmNwS1JnDG5J6ozBLUmdMbglqTMGtyR1xuCWpM4Y3JLUGYNbkjpjcEtSZwxuSeqMwS1JnTG4JakzSwZ3kvuTnElydKjt8iQHkzzVtpe19iT5WJITSY4kecski5ekaTTOHfcngJvParsTOFRVO4BD7RjgHcCO9tgL3Ls6ZUqSFi0Z3FX1N8APz2reDexv+/uBdw61f7IGvgJcmmTzahUrSVr+HPdVVXUaoG2vbO1bgKeH+s23tldIsjfJXJK5hYWFZZYhSdNntX85mRFtNapjVe2rqtmqmp2ZmVnlMiRp41pucD+zOAXStmda+zywbajfVuDU8suTJJ1tucF9ANjT9vcADw21v6etLtkFPL84pSJJWh0XLdUhyaeBG4ErkswDfwT8MfBgktuB7wPvbt0fAW4BTgA/Bd47gZolaaotGdxVdds5Tr1tRN8C7lhpUZKkc/OTk5LUGYNbkjpjcEtSZwxuSeqMwS1JnTG4JakzBrckdcbglqTOGNyS1BmDW5I6Y3BLUmcMbknqjMEtSZ0xuCWpMwa3JHXG4JakzhjcktQZg1uSOrNkcCe5P8mZJEeH2j6c5O+SHG6PW4bO3ZXkRJInk/zOpAqXpGk1zh33J4CbR7TfU1U72+MRgCTXArcCv96u+S9JNq1WsZKkMYK7qv4G+OGYz7cbeKCqXqiq7zH4tvfrV1CfJOksK5njfn+SI20q5bLWtgV4eqjPfGt7hSR7k8wlmVtYWFhBGZI0XZYb3PcCvwzsBE4Df9raM6JvjXqCqtpXVbNVNTszM7PMMiRp+iwruKvqmap6qap+Bvw5L0+HzAPbhrpuBU6trERJ0rBlBXeSzUOHvw8srjg5ANya5JIk1wA7gMdXVqIkadhFS3VI8mngRuCKJPPAHwE3JtnJYBrkJPA+gKo6luRB4FvAi8AdVfXSZEqXpOm0ZHBX1W0jmu87T/+7gbtXUpQk6dz85KQkdcbglqTOGNyS1BmDW5I6Y3BLUmcMbknqjMEtSZ1Zch23pIEn9r3vFW3/ZO/H16ASTTvvuKUxjAptaa0Y3JLUGYNbkjpjcEtSZwxuaZn8xaTWisEtSZ0xuKUluKJE643BLUmdMbglqTMGtyR1ZsngTrItyaNJjic5luQDrf3yJAeTPNW2l7X2JPlYkhNJjiR5y6QHIb3aXFGitTTOHfeLwIeq6k3ALuCOJNcCdwKHqmoHcKgdA7yDwbe77wD2AveuetWSNMWWDO6qOl1VX2v7PwaOA1uA3cD+1m0/8M62vxv4ZA18Bbg0yeZVr1x6FbiiROvRBc1xJ9kOXAc8BlxVVadhEO7Ala3bFuDpocvmW9vZz7U3yVySuYWFhQuvXJKm1NjBneT1wGeBD1bVj87XdURbvaKhal9VzVbV7MzMzLhlSNLUGyu4k1zMILQ/VVWfa83PLE6BtO2Z1j4PbBu6fCtwanXKlSSNs6okwH3A8ar66NCpA8Cetr8HeGio/T1tdcku4PnFKRVpI3BFidbaON+AcwPwB8A3kxxubX8I/DHwYJLbge8D727nHgFuAU4APwXeu6oVS9KUWzK4q+rLjJ63BnjbiP4F3LHCuiRJ5+AnJ6VzcCmg1iuDW5I6Y3BLUmcMbukCuKJE64HBLUmdMbglqTMGtzSCK0q0nhncktQZg1uSOmNwS1JnDG5pTC4F1HphcEtSZwxuSeqMwS2dZdRSQKdJtJ4Y3JLUGYNbGuIHb9QDg1uSOmNwS1Jnxvmy4G1JHk1yPMmxJB9o7R9O8ndJDrfHLUPX3JXkRJInk/zOJAcgSdNmnC8LfhH4UFV9LckbgCeSHGzn7qmq/zjcOcm1wK3ArwP/APifSX61ql5azcKlV4srSrTeLHnHXVWnq+prbf/HwHFgy3ku2Q08UFUvVNX3GHzb+/WrUawk6QLnuJNsB64DHmtN709yJMn9SS5rbVuAp4cum+f8QS9JugBjB3eS1wOfBT5YVT8C7gV+GdgJnAb+dLHriMtrxPPtTTKXZG5hYeGCC5dWm0sB1YuxgjvJxQxC+1NV9TmAqnqmql6qqp8Bf87L0yHzwLahy7cCp85+zqraV1WzVTU7MzOzkjFI0lQZZ1VJgPuA41X10aH2zUPdfh842vYPALcmuSTJNcAO4PHVK1mSpts4q0puAP4A+GaSw63tD4HbkuxkMA1yEngfQFUdS/Ig8C0GK1LucEWJeuWKEq1HSwZ3VX2Z0fPWj5znmruBu1dQlyTpHPzkpCR1xuCWcEWJ+mJwS1JnDG5J6ozBLUmdMbilc3ApoNYrg1uSOmNwa+q5okS9MbglqTMGtyR1xuCWpM4Y3NIIrijRemZwS1JnxvmzrlJXBn9CfjxzH9+7oueoesWXO0kT5x23JHXGO25NvYdPv3zX/bub961hJdJ4vOPWVBsO7VHH0npkcEtnmX2fd91a38b5suDXJnk8yTeSHEvykdZ+TZLHkjyV5DNJXtPaL2nHJ9r57ZMdgiRNl3HuuF8AbqqqNwM7gZuT7AL+BLinqnYAzwK3t/63A89W1a8A97R+0rp09py2c9zqwThfFlzAT9rhxe1RwE3Av2jt+4EPA/cCu9s+wF8B/ylJynVTWocG0yIvh/WH16wSaXxjzXEn2ZTkMHAGOAh8B3iuql5sXeaBLW1/C/A0QDv/PPDG1SxakqbZWMFdVS9V1U5gK3A98KZR3dp21CcXXnG3nWRvkrkkcwsLC+PWK0lT74JWlVTVc8CXgF3ApUkWp1q2Aqfa/jywDaCd/0XghyOea19VzVbV7MzMzPKql6QpNM6qkpkkl7b91wFvB44DjwLvat32AA+1/QPtmHb+i85vS9LqGeeTk5uB/Uk2MQj6B6vq4STfAh5I8h+ArwP3tf73Af8tyQkGd9q3TqBuSZpa46wqOQJcN6L9uwzmu89u/9/Au1elOknSK/jJSUnqjMEtSZ0xuCWpM/5ZV204LmLSRucdtyR1xuCWpM4Y3JLUGYNbkjpjcEtSZwxuSeqMwS1JnTG4JakzBrckdcbglqTOGNyS1BmDW5I6Y3BLUmcMbknqzDhfFvzaJI8n+UaSY0k+0to/keR7SQ63x87WniQfS3IiyZEkb5n0ICRpmozz97hfAG6qqp8kuRj4cpL/3s7966r6q7P6vwPY0R5vBe5tW0nSKljyjrsGftIOL26P8/2l+t3AJ9t1XwEuTbJ55aVKkmDMOe4km5IcBs4AB6vqsXbq7jYdck+SS1rbFuDpocvnW5skaRWMFdxV9VJV7QS2Atcn+UfAXcCvAf8UuBz4t617Rj3F2Q1J9iaZSzK3sLCwrOIlaRpd0KqSqnoO+BJwc1WdbtMhLwD/Fbi+dZsHtg1dthU4NeK59lXVbFXNzszMLKt4SZpG46wqmUlyadt/HfB24NuL89ZJArwTONouOQC8p60u2QU8X1WnJ1K9JE2hcVaVbAb2J9nEIOgfrKqHk3wxyQyDqZHDwL9q/R8BbgFOAD8F3rv6ZUvS9FoyuKvqCHDdiPabztG/gDtWXpokaRQ/OSlJnTG4JakzBrckdcbglqTOGNyS1BmDW5I6Y3BLUmcMbknqjMEtSZ0xuCWpMwa3JHXG4JakzhjcktQZg1uSOmNwS1JnDG5J6ozBLUmdMbglqTMGtyR1xuCWpM4Y3JLUGYNbkjqTqlrrGkjyY+DJta5jQq4AfrDWRUzARh0XbNyxOa6+/MOqmhl14qJXu5JzeLKqZte6iElIMrcRx7ZRxwUbd2yOa+NwqkSSOmNwS1Jn1ktw71vrAiZoo45to44LNu7YHNcGsS5+OSlJGt96ueOWJI1pzYM7yc1JnkxyIsmda13PhUpyf5IzSY4OtV2e5GCSp9r2staeJB9rYz2S5C1rV/n5JdmW5NEkx5McS/KB1t712JK8NsnjSb7RxvWR1n5NksfauD6T5DWt/ZJ2fKKd376W9S8lyaYkX0/ycDveKOM6meSbSQ4nmWttXb8XV2JNgzvJJuA/A+8ArgVuS3LtWta0DJ8Abj6r7U7gUFXtAA61YxiMc0d77AXufZVqXI4XgQ9V1ZuAXcAd7b9N72N7Abipqt4M7ARuTrIL+BPgnjauZ4HbW//bgWer6leAe1q/9ewDwPGh440yLoDfrKqdQ0v/en8vLl9VrdkD+A3gC0PHdwF3rWVNyxzHduDo0PGTwOa2v5nBOnWAjwO3jeq33h/AQ8BvbaSxAX8f+BrwVgYf4Liotf/8fQl8AfiNtn9R65e1rv0c49nKIMBuAh4GshHG1Wo8CVxxVtuGeS9e6GOtp0q2AE8PHc+3tt5dVVWnAdr2ytbe5Xjbj9HXAY+xAcbWphMOA2eAg8B3gOeq6sXWZbj2n4+rnX8eeOOrW/HY/gz4N8DP2vEb2RjjAijgr5M8kWRva+v+vbhca/3JyYxo28jLXLobb5LXA58FPlhVP0pGDWHQdUTbuhxbVb0E7ExyKfB54E2jurVtF+NK8rvAmap6IsmNi80junY1riE3VNWpJFcCB5N8+zx9exvbBVvrO+55YNvQ8Vbg1BrVspqeSbIZoG3PtPauxpvkYgah/amq+lxr3hBjA6iq54AvMZjDvzTJ4o3McO0/H1c7/4vAD1/dSsdyA/B7SU4CDzCYLvkz+h8XAFV1qm3PMPjH9no20HvxQq11cH8V2NF+8/0a4FbgwBrXtBoOAHva/h4G88OL7e9pv/XeBTy/+KPeepPBrfV9wPGq+ujQqa7HlmSm3WmT5HXA2xn8Mu9R4F2t29njWhzvu4AvVps4XU+q6q6q2lpV2xn8f/TFqvqXdD4ugCS/kOQNi/vAbwNH6fy9uCJrPckO3AL8LYN5xn+31vUso/5PA6eB/8vgX/rbGcwVHgKeatvLW98wWEXzHeCbwOxa13+ecf0zBj9eHgEOt8ctvY8N+MfA19u4jgL/vrX/EvA4cAL4S+CS1v7adnyinf+ltR7DGGO8EXh4o4yrjeEb7XFsMSd6fy+u5OEnJyWpM2s9VSJJukAGtyR1xuCWpM4Y3JLUGYNbkjpjcEtSZwxuSeqMwS1Jnfl/jEoNpFt4LDkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nb_episodes = 20\n",
    "nb_timesteps = 100\n",
    "img = plt.imshow(env.render(mode='rgb_array')) # only call this once\n",
    "\n",
    "for episode in range(nb_episodes):  # iterate over the episodes\n",
    "    state = env.reset()             # initialise the environment\n",
    "    rewards = []\n",
    "    \n",
    "    for t in range(nb_timesteps):    # iterate over time steps\n",
    "        #env.render()                 # display the environment\n",
    "        img.set_data(env.render(mode='rgb_array')) # just update the data\n",
    "        display.display(plt.gcf())\n",
    "        display.clear_output(wait=True)\n",
    "        state, reward, done, info = env.step(0)  # implement the action chosen by the policy\n",
    "        rewards.append(reward)      # add 1 to the rewards list\n",
    "        \n",
    "        if done: # the episode ends either if the pole is > 15 deg from vertical or the cart move by > 2.4 unit from the centre\n",
    "            cumulative_reward = sum(rewards)\n",
    "            print(\"episode {} finished after {} timesteps. Total reward: {}\".format(episode, t+1, cumulative_reward))  \n",
    "            break\n",
    "    \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "- useful links\n",
    "    - how to initialize to a custom state: https://stackoverflow.com/questions/57263759/how-can-i-start-the-environment-from-a-custom-initial-state-for-mountain-car"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
