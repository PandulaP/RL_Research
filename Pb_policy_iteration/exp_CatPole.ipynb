{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "- useful links\n",
    "    - how to initialize to a custom state: https://stackoverflow.com/questions/57263759/how-can-i-start-the-environment-from-a-custom-initial-state-for-mountain-car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "from IPython.display import HTML\n",
    "import gym\n",
    "from gym import wrappers\n",
    "import io\n",
    "import base64\n",
    "import itertools\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**State observation**:\n",
    "    \n",
    "    Type: Box(4)\n",
    "\n",
    "    Num     Observation               Min                     Max\n",
    "    0       Cart Position             -4.8                    4.8\n",
    "    1       Cart Velocity             -Inf                    Inf\n",
    "    2       Pole Angle                -0.418 rad (-24 deg)    0.418 rad (24 deg)\n",
    "    3       Pole Angular Velocity     -Inf                    Inf\n",
    "\n",
    "- For this project, I will describe the state of the pendulum using only the angle and angular velocity of the pole, ignoring the position and the velocity of cart.\n",
    "\n",
    "**Actions**:\n",
    "\n",
    "    Type: Discrete(2)\n",
    "    \n",
    "    Num   Action\n",
    "    0     Push cart to the left\n",
    "    1     Push cart to the right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of actions: 2\n",
      "Observation space: Box(4,)\n",
      "Max. values of observation space:[4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38]\n",
      "Min. values of observation space:[-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38]\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('CartPole-v0')\n",
    "env.reset()\n",
    "\n",
    "print(\"Number of actions: \" + str(env.action_space.n))\n",
    "print(\"Observation space: \" + str(env.observation_space))\n",
    "print(\"Max. values of observation space:\" + str(env.observation_space.high))\n",
    "print(\"Min. values of observation space:\" + str(env.observation_space.low))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def state_filter(state):\n",
    "    \"\"\" only use the angle and the angular velocity of the pole to describe the state\"\"\"\n",
    "    \n",
    "    return state[[2,3]]\n",
    "\n",
    "\n",
    "def random_action(state):\n",
    "    \"\"\" return a random action: either 0 (left) or 1 (right)\"\"\"\n",
    "    \n",
    "    action = env.action_space.sample()  \n",
    "    return action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I generate random samples $S$ in this setting by simulating a uniform random number (max 100) of uniform random actions from the initial state. If the pendulum fell within this sequence, the procedure was repeated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_init_states_S(seed, filter_state=True):\n",
    "    \"\"\"this function returns a list of randomly generated initial states from the CartPole-v0 environment \"\"\"\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    n_actions = np.random.randint(low=1, high=101)                # how many actions to generate\n",
    "    seq_actions = np.random.randint(low=0,high=2,size=n_actions)  # random sequence of actions\n",
    "\n",
    "    init_states_S = []   # to store initial states\n",
    "\n",
    "    env = gym.make('CartPole-v0')\n",
    "    env.reset()\n",
    "\n",
    "    for action in seq_actions:\n",
    "\n",
    "        state, reward, done, info = env.step(action)  # implement the actions in the random sequence\n",
    "        \n",
    "        if filter_state:\n",
    "            init_states_S.append(state_filter(state)) # append the environment state to list (only angular velocity and angle)\n",
    "        else:\n",
    "            init_states_S.append(state) # all 4 state observations\n",
    "            \n",
    "        if done: # the episode ends either if the pole is > 15 deg from vertical or the cart move by > 2.4 unit from the centre\n",
    "            env.reset()    \n",
    "            \n",
    "    env.close()\n",
    "            \n",
    "    return init_states_S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Generate a sequence of intial states (for $S$) and display first 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABH0AAAEzCAYAAACsfH8PAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3db4ilZ33/8c+32URtFGN0I0s2NIoL6oNW42AjliJRSwzyiw8UIqUuJbDSWlBaKPFXaCv0gfaBiiDq/ogkFuufVktCSLEhRkofGN1oEhO3MauEZklwN2iipfRP7PV7MPfqMM5mZ3bPOXOd67xecDjn3HPnvu45M28l39znTLXWAgAAAMBYfmW3TwAAAACA2TP0AQAAABiQoQ8AAADAgAx9AAAAAAZk6AMAAAAwIEMfAAAAgAHNZehTVVdX1UNVdayqbpjHGsDOaRP6pE3okzahT9qE7avW2mwPWHVeku8leXOS40m+meSdrbXvznQhYEe0CX3SJvRJm9AnbcLOzONKn9cmOdZa+0Fr7b+TfD7JtXNYB9gZbUKftAl90ib0SZuwA/MY+lya5NENz49P24DdpU3okzahT9qEPmkTdmDPHI5ZW2z7pfeQVdWhJIeS5MILL3zNy1/+8jmcCvThkUceyRNPPLFVG4ukTdhEm9AnbUKftAl9eqY25zH0OZ7ksg3P9yd5bPNOrbXDSQ4nydraWjty5MgcTgX6sLa2ttunkGgTfok2oU/ahD5pE/r0TG3O4+1d30xyoKpeUlUXJLkuya1zWAfYGW1Cn7QJfdIm9EmbsAMzv9KntfZ0Vf1Rkq8kOS/Jp1trD856HWBntAl90ib0SZvQJ23Czszj7V1prd2e5PZ5HBs4e9qEPmkT+qRN6JM2Yfvm8fYuAAAAAHaZoQ8AAADAgAx9AAAAAAZk6AMAAAAwIEMfAAAAgAEZ+gAAAAAMyNAHAAAAYECGPgAAAAADMvQBAAAAGJChDwAAAMCADH0AAAAABmToAwAAADAgQx8AAACAARn6AAAAAAzI0AcAAABgQIY+AAAAAAMy9AEAAAAYkKEPAAAAwIAMfQAAAAAGZOgDAAAAMCBDHwAAAIABGfoAAAAADOiMQ5+q+nRVnaiqBzZsu7iq7qiqh6f7F0zbq6o+VlXHqur+qrpinicPq0yb0CdtQp+0CX3SJszXdq70uSnJ1Zu23ZDkztbagSR3Ts+T5C1JDky3Q0k+MZvTBLZwU7QJPbop2oQe3RRtQo9uijZhbs449Gmt/XOSH23afG2Sm6fHNyd524btn2nrvp7koqraN6uTBX5Bm9AnbUKftAl90ibM19l+ps+LW2uPJ8l0f8m0/dIkj27Y7/i0DVgMbUKftAl90ib0SZswI7P+IOfaYlvbcseqQ1V1pKqOnDx5csanAWyiTeiTNqFP2oQ+aRN26GyHPj88dRnddH9i2n48yWUb9tuf5LGtDtBaO9xaW2utre3du/csTwPYRJvQJ21Cn7QJfdImzMjZDn1uTXJwenwwyS0btr9r+lT1K5M8deqyPGAhtAl90ib0SZvQJ23CjOw50w5V9bkkb0jyoqo6nuQvknwwyRer6vok/5bkHdPutye5JsmxJP+R5PfncM5AtAm90ib0SZvQJ23CfJ1x6NNae+dpvvTGLfZtSd5zricFnJk2oU/ahD5pE/qkTZivWX+QMwAAAAAdMPQBAAAAGJChDwAAAMCADH0AAAAABmToAwAAADAgQx8AAACAARn6AAAAAAzI0AcAAABgQIY+AAAAAAMy9AEAAAAYkKEPAAAAwIAMfQAAAAAGZOgDAAAAMCBDHwAAAIABGfoAAAAADMjQBwAAAGBAhj4AAAAAAzL0WVH3HH73bp8CsAVtQp+0CX3SJvRHl33Zs9snwGIJEPqkTeiTNqFP2oT+6LJPrvQBAAAAGJChDwAAAMCADH0AAACAmfFWr36ccehTVZdV1V1VdbSqHqyq907bL66qO6rq4en+BdP2qqqPVdWxqrq/qq6Y9zcBq0ib0CdtQp+0CX3S5jhec+hTu30KbGE7V/o8neRPWmuvSHJlkvdU1SuT3JDkztbagSR3Ts+T5C1JDky3Q0k+MfOzBhJtQq+0CX3SJvRJmzBHZxz6tNYeb619a3r80yRHk1ya5NokN0+73ZzkbdPja5N8pq37epKLqmrfzM8cVpw2oU/ahD5pE/qkTZivHX2mT1VdnuTVSe5O8uLW2uPJeqhJLpl2uzTJoxv+sePTNmBOtAl90ib0SZvQJ23C7G176FNVz03ypSTva6395Jl23WJb2+J4h6rqSFUdOXny5HZPA9hEm9AnbUKftAl90ibMx7aGPlV1ftYD/Gxr7cvT5h+euoxuuj8xbT+e5LIN//j+JI9tPmZr7XBrba21trZ3796zPX9YadqEPmkT+qRN6JM2YX6289e7KsmNSY621j684Uu3Jjk4PT6Y5JYN2981far6lUmeOnVZHjA72oQ+aRP6pE3okzZhvvZsY5/XJ/m9JN+pqnunbf83yQeTfLGqrk/yb0neMX3t9iTXJDmW5D+S/P5Mzxg4RZvQJ21Cn7QJfdImzNEZhz6ttX/J1u+bTJI3brF/S/Keczwv4Ay0CX3SJvRJm9AnbcJ87eivdwEAAACwHAx9AAAAAAZk6AMAAAAwIEMfAAAAgAEZ+gAAAAAMyNAHAAAAYECGPgAAAAADMvQBAAAAGJChDwAAAMCADH0AAAAABmToAwAAADAgQx8AAACAARn6AAAAAAzI0AcAAABgQIY+AADbcM/hd+/2KQAA7IihD0Bn/IslAAAwC4Y+AADA0vIfSwBOz9Bnhfk/SAAAABiXoQ8AAADAgAx9AAAAgJnyzpI+GPoAAAAADMjQZ1BVteXtbPcDZkOb0CdtQp+0CX3S5vI449Cnqp5dVd+oqvuq6sGq+sC0/SVVdXdVPVxVX6iqC6btz5qeH5u+fvl8vwV26rbHD+W2xw/t9mlwjrQ5Hm2OQZvj0eYYtDkebY5Bm+PRZl+2c6XPfyW5qrX2G0leleTqqroyyYeSfKS1diDJj5NcP+1/fZIft9ZeluQj0350YmN8Qlx62hyINoeizYFocyjaHIg2h6LNgWizP2cc+rR1/z49PX+6tSRXJfn7afvNSd42Pb52ep7p628s12914637Dm/5mOWjzbFocxzaHIs2x6HNsWhzHNocizb7s2c7O1XVeUnuSfKyJB9P8v0kT7bWnp52OZ7k0unxpUkeTZLW2tNV9VSSFyZ5YobnzVlae/fhJOvx/eWungmzoM1xaHMs2hyHNseizXFocyzaHIc2+7OtD3Jurf2stfaqJPuTvDbJK7babbrfasraNm+oqkNVdaSqjpw8eXK75wtsoE3okzahT9qEPmkT5mdHf72rtfZkkq8luTLJRVV16kqh/Ukemx4fT3JZkkxff36SH21xrMOttbXW2trevXvP7uyBJNqEXmkT+qRN6JM2Yfa289e79lbVRdPj5yR5U5KjSe5K8vZpt4NJbpke3zo9z/T1r7bWfmnyCpwbbUKftAl90ib0SZswX9v5TJ99SW6e3mf5K0m+2Fq7raq+m+TzVfVXSb6d5MZp/xuT/E1VHcv6xPW6OZw3oE3olTahT9qEPmkT5uiMQ5/W2v1JXr3F9h9k/f2Wm7f/Z5J3zOTsgNPSJvRJm9AnbUKftAnzta2/3sXycYUj9Emb0CdtQp+0CX3S5vLY0Qc5AwAAALAcDH0AAAAABmToAwAAADAgQx8AAACAARn6AAAAAAzI0AcAAABgQIY+AAAAAAMy9AEAAAAYkKEPAAAAwIAMfQAAAAAGZOgDAAAAMCBDHwAAAIABGfoAAAAADMjQBwAAAGBAhj4AAAAAAzL0AQAAABiQoQ8AAADAgAx9AAAAAAZk6AMAAAAwIEMfAAAAgAEZ+gAAAAAMyNAHAAAAYECGPgAAAAADMvQBAAAAGJChDwAAAMCAqrW22+eQqvppkod2afkXJXnC2taes19rre3dhXXPiTatvQJra3PnVvH3ZFXX3s3vWZs7t4q/o7u59ip+z4k2z8Yq/q6s4ve822ufts09iz6T03iotba2GwtX1RFrW5vT0qa1h197SWnT2sOuu+S0uSJrr+L3vOS0uQLrrvLaz8TbuwAAAAAGZOgDAAAAMKBehj6HrW3tFVh7Ga3qz8raq7X2MlrVn5W1V2PdZbaKvyeruvYqfs/LbFV/XvpYnbVPq4sPcgYAAABgtnq50gcAAACAGdr1oU9VXV1VD1XVsaq6YQ7H/3RVnaiqBzZsu7iq7qiqh6f7F0zbq6o+Np3L/VV1xTmse1lV3VVVR6vqwap67wLXfnZVfaOq7pvW/sC0/SVVdfe09heq6oJp+7Om58emr19+tmtvOIfzqurbVXXbIteuqkeq6jtVdW9VHZm2zf01H5E2tanNPmlTm9rsz6hdTsfTpjaXljbHbHO3upyOuXxtttZ27ZbkvCTfT/LSJBckuS/JK2e8xm8nuSLJAxu2/XWSG6bHNyT50PT4miT/mKSSXJnk7nNYd1+SK6bHz0vyvSSvXNDaleS50+Pzk9w9HfOLSa6btn8yyR9Mj/8wySenx9cl+cIMXvc/TvK3SW6bni9k7SSPJHnRpm1zf81Hu2lTm9rs86ZNbWqzv9vIXU7H06Y2l/KmzXHb3K0up+MsXZsLX3DTi/O6JF/Z8Pz9Sd4/h3Uu3xTiQ0n2TY/3JXloevypJO/car8ZnMMtSd686LWT/GqSbyX5zSRPJNmz+bVP8pUkr5se75n2q3NYc3+SO5NcleS26Zd8UWtvFeHCf97LftOmNrXZ502b2tRmf7dV6nI6nja1uRQ3bY7Z5m52OR1n6drc7bd3XZrk0Q3Pj0/b5u3FrbXHk2S6v2Se5zNdRvbqrE9AF7L2dMnbvUlOJLkj61PuJ1trT29x/J+vPX39qSQvPNu1k3w0yZ8m+d/p+QsXuHZL8k9VdU9VHZq2LfTnPQhtalObfdKmNrXZn5XoMtFmtLlstDlmm7vZZbKEbe5Z9IKb1Bbb2sLP4hdmfj5V9dwkX0ryvtbaT6q2WmL2a7fWfpbkVVV1UZJ/SPKKZzj+zNauqrcmOdFau6eq3rCN48/6NX99a+2xqrokyR1V9a/PsG9vv3896e210eY5rq3NYfT22mjzHNfW5hB6e13mcj7aPOPxtdmf3l4XbZ7j2h10mSxhm7t9pc/xJJdteL4/yWMLWPeHVbUvSab7E/M4n6o6P+sBfra19uVFrn1Ka+3JJF/L+nsIL6qqU4O+jcf/+drT15+f5EdnueTrk/yfqnokyeezftndRxe0dlprj033J7L+Pz6vzYJf80FoU5va7JM2tanN/gzd5XR8bWpzGWlzvDZ3tctkOdvc7aHPN5McqPVP274g6x+udOsC1r01ycHp8cGsv//x1PZ31borkzx16jKtnar1EeuNSY621j684LX3ThPXVNVzkrwpydEkdyV5+2nWPnVOb0/y1Ta96XCnWmvvb63tb61dnvWf51dba7+7iLWr6sKqet6px0l+J8kDWcBrPiBtalObfdKmNrXZn2G7TLSpzaWmzcHa3M0ukyVusy34Q4Q237L+idbfy/p7AP9sDsf/XJLHk/xP1idt12f9fXx3Jnl4ur942reSfHw6l+8kWTuHdX8r65du3Z/k3ul2zYLW/vUk357WfiDJn0/bX5rkG0mOJfm7JM+atj97en5s+vpLZ/TavyG/+ET1ua89rXHfdHvw1O/TIl7zEW/a1KY2+7xpU5va7O82apfT8bSpzaW9aXPcNhfd5YZ1lq7Nmk4GAAAAgIHs9tu7AAAAAJgDQx8AAACAARn6AAAAAAzI0AcAAABgQHMZ+lTV1VX1UFUdq6ob5rEGsHPahD5pE/qkTeiTNmH7Zv7Xu6rqvKz/Wbw3Z/3P1n0zyTtba9+d6ULAjmgT+qRN6JM2oU/ahJ2Zx5U+r01yrLX2g9bafyf5fJJr57AOsDPahD5pE/qkTeiTNmEH5jH0uTTJoxueH5+2AbtLm9AnbUKftAl90ibswJ45HLO22PZL7yGrqkNJDiXJhRde+JqXv/zlczgV6MMjjzySJ554Yqs2FkmbsIk2oU/ahD5pE/r0TG3OY+hzPMllG57vT/LY5p1aa4eTHE6StbW1duTIkTmcCvRhbW1tt08h0Sb8Em1Cn7QJfdIm9OmZ2pzH27u+meRAVb2kqi5Icl2SW+ewDrAz2oQ+aRP6pE3okzZhB2Z+pU9r7emq+qMkX0lyXpJPt9YenPU6wM5oE/qkTeiTNqFP2oSdmcfbu9Jauz3J7fM4NnD2tAl90ib0SZvQJ23C9s3j7V0AAAAA7DJDHwAAAIABGfoAAAAADMjQBwAAAGBAhj4AAAAAAzL0AQAAABiQoQ8AAADAgAx9AAAAAAZk6AMAAAAwIEMfAAAAgAEZ+gAAAAAMyNAHAAAAYECGPgAAAAADMvQBAAAAGJChDwAAAMCADH0AAAAABmToAwAAADAgQx8AAACAARn6AAAAAAzI0AcAAABgQIY+AAAAAAMy9AEAAAAY0BmHPlX16ao6UVUPbNh2cVXdUVUPT/cvmLZXVX2sqo5V1f1VdcU8Tx5WmTahT9qEPmkT+qRNmK/tXOlzU5KrN227IcmdrbUDSe6cnifJW5IcmG6HknxiNqcJbOGmaBN6dFO0CT26KdqEHt0UbcLcnHHo01r75yQ/2rT52iQ3T49vTvK2Dds/09Z9PclFVbVvVicL/II2oU/ahD5pE/qkTZivs/1Mnxe31h5Pkun+kmn7pUke3bDf8WkbsBjahD5pE/qkTeiTNmFGZv1BzrXFtrbljlWHqupIVR05efLkjE8D2ESb0CdtQp+0CX3SJuzQ2Q59fnjqMrrp/sS0/XiSyzbstz/JY1sdoLV2uLW21lpb27t371meBrCJNqFP2oQ+aRP6pE2YkbMd+tya5OD0+GCSWzZsf9f0qepXJnnq1GV5wEJoE/qkTeiTNqFP2oQZ2XOmHarqc0nekORFVXU8yV8k+WCSL1bV9Un+Lck7pt1vT3JNkmNJ/iPJ78/hnIFoE3qlTeiTNqFP2oT5OuPQp7X2ztN86Y1b7NuSvOdcTwo4M21Cn7QJfdIm9EmbMF+z/iBnAAAAADpg6AMAAAAwIEMfAAAAgAEZ+gAAAAAMyNAHAAAAYECGPgAAAAADMvQBAAAAGJChDwAAAMCADH0AAAAABmToAwAAADAgQx8AAACAARn6AAAAAAzI0AcAAABgQIY+AAAAAAMy9AEAAAAYkKEPAAAAwIAMfQAAAAAGZOizgu45/O7dPgUAAABgzvbs9gmwOIY90J+NXb7m0Kd28UyAjbQJ/dEl9EeX/XOlDwAAAMCADH0AAACAc+KdJX0y9AEAAAAY0BmHPlV1WVXdVVVHq+rBqnrvtP3iqrqjqh6e7l8wba+q+lhVHauq+6vqinl/E7CKtDmGje999l9HxqBN6JM2oU/ahPnazpU+Tyf5k9baK5JcmeQ9VfXKJDckubO1diDJndPzJHlLkgPT7VCST8z8rIFEm9ArbUKftAl90uYS8+HN/Tvj0Ke19nhr7VvT458mOZrk0iTXJrl52u3mJG+bHl+b5DNt3deTXFRV+2Z+5rDitAl90ib0SZvQJ23CfO3oM32q6vIkr05yd5IXt9YeT9ZDTXLJtNulSR7d8I8dn7YBc6JN6JM2oU/ahD5pE2Zv20Ofqnpuki8leV9r7SfPtOsW29oWxztUVUeq6sjJkye3exrAJtqEPmkT+qTN5eVz8MamTZiPbQ19qur8rAf42dbal6fNPzx1Gd10f2LafjzJZRv+8f1JHtt8zNba4dbaWmttbe/evWd7/rDStAl90ib0SZvQJ23C/Gznr3dVkhuTHG2tfXjDl25NcnB6fDDJLRu2v2v6VPUrkzx16rI8YHa0CX3SJvRJm9AnbcJ8bedKn9cn+b0kV1XVvdPtmiQfTPLmqno4yZun50lye5IfJDmW5P8l+cPZnzYQbUKvtDkAbyMZkjahT9qEOdpzph1aa/+Srd83mSRv3GL/luQ953hewBloE/qkTeiTNqFP2oT52tFf7wIAAAA4xdWxfTP0AQAAABiQoc8KMYEFAACA1WHoAwAAADAgQx8AAGApuHIdYGcMfQAAAAAGZOgDsMv8V0sAAGAeDH0AAACAs+Y/YvbL0AcAAABgQIY+AAAAAAMy9AEA2IJL1QGAZWfoAwAAADAgQx8AAACAARn6AAAAS8NbLwG2z9AHAAAAYECGPgAAAMA5cRVenwx9AAAAAAZk6AMAAAAwIEMfAAAAgAEZ+gAAAAAMyNBnhflwLQAAABiXoc+gqmrL29nuB8zGdpq75/C7tQkLtp3mTrePNmF+tAl90ubyOOPQp6qeXVXfqKr7qurBqvrAtP0lVXV3VT1cVV+oqgum7c+anh+bvn75fL8Fduq2xw/ltscP7fZpcI60OR5tjkGb4znV5pFP6XOZaXM82hyDNsejzb5s50qf/0pyVWvtN5K8KsnVVXVlkg8l+Uhr7UCSHye5ftr/+iQ/bq29LMlHpv3oxMZ/ofQvl0tPmwPR5lC0ORBtDkWbA9HmULQ5EG3254xDn7bu36en50+3luSqJH8/bb85ydumx9dOzzN9/Y3l+q1uvHXf4S0fs3y0ORZtjkObY9HmOLQ5Fm2OQ5tj0WZ/9mxnp6o6L8k9SV6W5ONJvp/kydba09Mux5NcOj2+NMmjSdJae7qqnkrywiRPzPC8OUtr7z6cZD2+v9zVM2EWtDkObY5Fm+PQ5li0OQ5tjkWb49Bmf7b1Qc6ttZ+11l6VZH+S1yZ5xVa7TfdbTVnb5g1VdaiqjlTVkZMnT273fIENtAl90ib0SZvQJ23C/Ozor3e11p5M8rUkVya5qKpOXSm0P8lj0+PjSS5Lkunrz0/yoy2Odbi1ttZaW9u7d+/ZnT2QRJvQK21Cn7QJfdImzN52/nrX3qq6aHr8nCRvSnI0yV1J3j7tdjDJLdPjW6fnmb7+1dbaL01egXOjTeiTNqFP2oQ+aRPmazuf6bMvyc3T+yx/JckXW2u3VdV3k3y+qv4qybeT3Djtf2OSv6mqY1mfuF43h/MGtAm90ib0SZvQJ23CHJ1x6NNauz/Jq7fY/oOsv99y8/b/TPKOmZwdcFrahD5pE/qkTeiTNmG+tvXXu1g+rnCEPmkT+qRN6JM2oU/aXB47+iBnAAAAAJaDoQ8AAADAgAx9AAAAAAZk6AMAAAAwIEMfAAAAgAEZ+gAAAAAMyNAHAAAAYECGPgAAAAADMvQBAAAAGJChDwAAAMCADH0AAAAABmToAwAAADAgQx8AAACAARn6AAAAAAzI0AcAAABgQIY+AAAAAAMy9AEAAAAYkKEPAAAAwIAMfQAAAAAGZOgDAAAAMCBDHwAAAIABGfoAAAAADMjQBwAAAGBAhj4AAAAAAzL0AQAAABhQtdZ2+xxSVT9N8tAuLf+iJE9Y29pz9muttb27sO450aa1V2Btbe7cKv6erOrau/k9a3PnVvF3dDfXXsXvOdHm2VjF35VV/J53e+3Ttrln0WdyGg+11tZ2Y+GqOmJta3Na2rT28GsvKW1ae9h1l5w2V2TtVfyel5w2V2DdVV77mXh7FwAAAMCADH0AAAAABtTL0Oewta29Amsvo1X9WVl7tdZeRqv6s7L2aqy7zFbx92RV117F73mZrerPSx+rs/ZpdfFBzgAAAADMVi9X+gAAAAAwQ7s+9Kmqq6vqoao6VlU3zOH4n66qE1X1wIZtF1fVHVX18HT/gml7VdXHpnO5v6quOId1L6uqu6rqaFU9WFXvXeDaz66qb1TVfdPaH5i2v6Sq7p7W/kJVXTBtf9b0/Nj09cvPdu0N53BeVX27qm5b5NpV9UhVfaeq7q2qI9O2ub/mI9KmNrXZJ21qU5v9GbXL6Xja1ObS0uaYbe5Wl9Mxl6/N1tqu3ZKcl+T7SV6a5IIk9yV55YzX+O0kVyR5YMO2v05yw/T4hiQfmh5fk+Qfk1SSK5PcfQ7r7ktyxfT4eUm+l+SVC1q7kjx3enx+krunY34xyXXT9k8m+YPp8R8m+eT0+LokX5jB6/7HSf42yW3T84WsneSRJC/atG3ur/loN21qU5t93rSpTW32dxu5y+l42tTmUt60OW6bu9XldJyla3PhC256cV6X5Csbnr8/yfvnsM7lm0J8KMm+6fG+JA9Njz+V5J1b7TeDc7glyZsXvXaSX03yrSS/meSJJHs2v/ZJvpLkddPjPdN+dQ5r7k9yZ5Krktw2/ZIvau2tIlz4z3vZb9rUpjb7vGlTm9rs77ZKXU7H06Y2l+KmzTHb3M0up+MsXZu7/fauS5M8uuH58WnbvL24tfZ4kkz3l8zzfKbLyF6d9QnoQtaeLnm7N8mJJHdkfcr9ZGvt6S2O//O1p68/leSFZ7t2ko8m+dMk/zs9f+EC125J/qmq7qmqQ9O2hf68B6FNbWqzT9rUpjb7sxJdJtqMNpeNNsdscze7TJawzT2LXnCT2mJbW/hZ/MLMz6eqnpvkS0ne11r7SdVWS8x+7dbaz5K8qqouSvIPSV7xDMef2dpV9dYkJ1pr91TVG7Zx/Fm/5q9vrT1WVZckuaOq/vUZ9u3t968nvb022jzHtbU5jN5eG22e49raHEJvr8tczkebZzy+NvvT2+uizXNcu4MukyVsc7ev9Dme5LINz/cneWwB6/6wqvYlyXR/Yh7nU1XnZz3Az7bWvrzItU9prT2Z5GtZfw/hRVV1atC38fg/X3v6+vOT/Ogsl3x9kv9TVY8k+XzWL7v76ILWTmvtsen+RNb/x+e1WfBrPghtalObfdKmNrXZn6G7nI6vTW0uI22O1+audpksZ5u7PfT5ZpIDtf5p2xdk/cOVbl3AurcmOTg9Ppj19z+e2v6uWndlkqdOXaa1U7U+Yr0xydHW2ocXvPbeaeKaqnpOkjclOZrkriRvP83ap87p7Um+2qY3He5Ua+39rbX9rbXLs/7z/Gpr7XcXsXZVXVhVzzv1OMnvJHkgC3jNB6RNbWqzT9rUpjb7M2yXiTa1udS0OVibu9llssRttgV/iNDmW9Y/0fp7WX8P4J/N4fifS/J4kv/J+qTt+qy/jwxsGtcAAADLSURBVO/OJA9P9xdP+1aSj0/n8p0ka+ew7m9l/dKt+5PcO92uWdDav57k29PaDyT582n7S5N8I8mxJH+X5FnT9mdPz49NX3/pjF77N+QXn6g+97WnNe6bbg+e+n1axGs+4k2b2tRmnzdtalOb/d1G7XI6nja1ubQ3bY7b5qK73LDO0rVZ08kAAAAAMJDdfnsXAAAAAHNg6AMAAAAwIEMfAAAAgAEZ+gAAAAAMyNAHAAAAYECGPgAAAAADMvQBAAAAGJChDwAAAMCA/j/yAC9YoEGVFwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1440x360 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "init_states_S = generate_init_states_S(16) # randomly generated states initial\n",
    "\n",
    "env = gym.make('CartPole-v0') # create inv. pend environment\n",
    "env = env.unwrapped           # unwrap the environment to send custom initial states\n",
    "fig = plt.figure(figsize=(20,5))\n",
    "\n",
    "for i in range(10):\n",
    "    env.state = np.concatenate((np.array([0.0,0.0]),init_states_S[i])) # manually adding cart-posi & cart-velocity\n",
    "    fig.add_subplot(2,5,i+1)\n",
    "    plt.imshow(env.render(mode=\"rgb_array\"))\n",
    "    env.close()\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I partition the action space to create multiple actions, because in these cases it becomes less and less likely that a unique best actions can be found. The range of the original action set {0, 1} is partitioned equidistantly into the given number of actions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_action_space(env,n_actions):\n",
    "    \"\"\"this function partitions the action space of a given environment into a given number of `n_actions`\"\"\"\n",
    "    \n",
    "    actions = np.arange(env.action_space.n)\n",
    "\n",
    "    # a uniform noise term is added to action signals to make all state transitions non-deterministic\n",
    "    part_act_space = np.linspace(actions[0],actions[-1],n_actions) + np.random.uniform(low = -.2,high=.2) \n",
    "    \n",
    "    return part_act_space                                                                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original action space: 2\n",
      "Partitioned into 3 actions: [-0.12215384  0.37784616  0.87784616]\n",
      "Partitioned into 9 actions: [-0.09014737  0.03485263  0.15985263  0.28485263  0.40985263  0.53485263\n",
      "  0.65985263  0.78485263  0.90985263]\n",
      "Partitioned into 17 actions: [-0.14760155 -0.08510155 -0.02260155  0.03989845  0.10239845  0.16489845\n",
      "  0.22739845  0.28989845  0.35239845  0.41489845  0.47739845  0.53989845\n",
      "  0.60239845  0.66489845  0.72739845  0.78989845  0.85239845]\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('CartPole-v0')\n",
    "\n",
    "print(\"Original action space: \" + str(env.action_space.n))\n",
    "print(\"Partitioned into 3 actions: \" + str(partition_action_space(env,3)))\n",
    "print(\"Partitioned into 9 actions: \" + str(partition_action_space(env,9)))\n",
    "print(\"Partitioned into 17 actions: \" + str(partition_action_space(env,17)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preference-based Approximate Policy Iteration algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "### Evaluate-Preference procedure ###\n",
    "\n",
    "### Description:\n",
    "###  This is done using roll-outs\n",
    "###  At every state in the initial state set, roll-outs are generated from each action for the same policy\n",
    "###  Accumulated rewards from each roll-out from each action are used to generate preferences for every pair of actions\n",
    "###  Generated preferences are stored in the training set; training data are used to learn the LabelRanker\n",
    "\n",
    "### Functionality:\n",
    "### - INPUTS  : starting state (s), two-actions(a_k, a_j), (current) policy (\\pi), max. length of trajectoris (L)\n",
    "### - PROCESS : generate roll-out (fixed time horizon) and calculate accumulate reward\n",
    "### - OUTPUT  : compare return from each rollout: store preference info in training dataset as (s,a_k > a_j)\n",
    "\n",
    "### - Run this procedure for every action-pair at all initial-states\n",
    "\n",
    "def evaluate_preference(starting_state\n",
    "                        , action_1\n",
    "                        , action_2\n",
    "                        , policy\n",
    "                        , environment_name = 'CartPole-v0'\n",
    "                        , discount_fac = 0.99\n",
    "                        , n_rollouts = 10\n",
    "                        , max_rollout_len = 10\n",
    "                       ):\n",
    "    \n",
    "    policy = policy              # policy to follow in roll-outs\n",
    "    n_rollouts = n_rollouts      # number of roll-outs to generate\n",
    "    gamma = discount_fac         # discount factor\n",
    "\n",
    "    # state is 4 dimensional by default: if only 2 give, has to expand to 4 dimensions\n",
    "    if len(starting_state) == 2:\n",
    "        # manually define state-values for 'cart-position' & 'cart-velocity'\n",
    "        cart_posi, cart_velo = 0,0   \n",
    "        s_init = np.concatenate((np.array([cart_posi,cart_velo]),starting_state))\n",
    "    else:\n",
    "        s_init = starting_state\n",
    "        \n",
    "    # dict. to store actions\n",
    "    actions = { 'one' : action_1 \n",
    "              , 'two' : action_2}    \n",
    "\n",
    "    # dict to store  rewards of roll-outs starting from each action\n",
    "    r = { 'one' : [None]*n_rollouts \n",
    "        , 'two' : [None]*n_rollouts}  \n",
    "\n",
    "    # dict to store average discounted return for for each action\n",
    "    avg_r = {}  \n",
    "\n",
    "    max_traj_len = max_rollout_len # maximum roll-out trajectory length\n",
    "\n",
    "    for action_key, action_value in actions.items():\n",
    "\n",
    "        # generate roll-outs\n",
    "        for rollout in range(n_rollouts):\n",
    "\n",
    "            env = gym.make(environment_name)\n",
    "            env = env.unwrapped\n",
    "\n",
    "            env.state = s_init  # set the starting state\n",
    "\n",
    "            # absolute of the rounded action value is applied in case action space is partitioned\n",
    "            #print(abs(round(action_value)))\n",
    "            observation, reward, done, info = env.step(int(abs(round(action_value))))\n",
    "\n",
    "            r[action_key][rollout] = reward # add the immediate reward of the action\n",
    "\n",
    "            traj_len = 1\n",
    "            while traj_len < max_traj_len and not done:\n",
    "\n",
    "                observation, reward, done, info = env.step(policy(observation)) ### NEED TO DEFINE A POLICY\n",
    "\n",
    "                r[action_key][rollout] += (gamma**traj_len) * reward\n",
    "\n",
    "                traj_len += 1\n",
    "\n",
    "            env.reset()\n",
    "            env.close()\n",
    "\n",
    "        # calculate average discounted return \n",
    "        avg_r[action_key]  = sum(r[action_key]) / len(r[action_key])\n",
    "\n",
    "    # return preference info. to generate training data\n",
    "    if avg_r['one'] > avg_r['two']:\n",
    "        return {'state': s_init[[2,3]] if len(s_init)>2 else s_init # only use the angel and velocity of pendulum for state\n",
    "               , 'a_k_prefered_a_j' : [actions['one'],actions['two']]\n",
    "               , 'preference_label' : 1}\n",
    "    elif avg_r['two'] > avg_r['one']:\n",
    "        return {'state': s_init[[2,3]] if len(s_init)>2 else s_init  # only use the angel and velocity of pendulum for state\n",
    "               , 'a_k_prefered_a_j' : [actions['two'],actions['one']]\n",
    "               , 'preference_label' : 1}\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': array([-0.02571933, -0.00185898]),\n",
       " 'a_k_prefered_a_j': [0.3, 0.6],\n",
       " 'preference_label': 1}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_preference(env.reset(),0.3,0.6,random_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21it [00:32,  1.56s/it]                                                                                                \n"
     ]
    }
   ],
   "source": [
    "###################################################\n",
    "### Preference-Based Policy Iteration Algorithm ###\n",
    "\n",
    "### Functionality:\n",
    "### - INPUTS  : sample states (s'), initial (random) policy (\\pi0), max. num. of policy iterations (p)\n",
    "### - PROCESS : generate roll-out (fixed time horizon) and calculate accumulate reward\n",
    "### - OUTPUT  : compare return from each rollout: store preference info in training dataset as (s,a_k > a_j)\n",
    "\n",
    "\n",
    "# initialize environment\n",
    "env = gym.make('CartPole-v0')\n",
    "\n",
    "# initial random policy\n",
    "policy_init = random_action\n",
    "policy = policy_init\n",
    "\n",
    "# sample states\n",
    "sample_states = generate_init_states_S(seed = 16) # randomly generated states initial\n",
    "\n",
    "# maximum number of policy iterations\n",
    "max_iterr = 20\n",
    "\n",
    "# action space to consider\n",
    "act_space = partition_action_space(env,3)\n",
    "\n",
    "# generate action-pairs (per each)\n",
    "act_pairs = list(itertools.combinations(act_space,2))\n",
    "\n",
    "# place-holder for training data\n",
    "train_data = []\n",
    "\n",
    "iterr = 0\n",
    "\n",
    "pbar = tqdm.tqdm(total=max_iterr)\n",
    "\n",
    "while iterr <= max_iterr:\n",
    "    \n",
    "    for state in sample_states:\n",
    "        \n",
    "        for action_pair in act_pairs:\n",
    "            preference_out = evaluate_preference(state, action_pair[0], action_pair[1], policy)\n",
    "            \n",
    "            if preference_out is not None:\n",
    "                train_data.append(preference_out)\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "    pbar.update(1)\n",
    "    iterr += 1\n",
    "    \n",
    "    \n",
    "pbar.close()\n",
    "\n",
    "### Train LaberRanker using train-data\n",
    "### Create new policy using LabeRanker\n",
    "### Re-run loop with new policy\n",
    "\n",
    "        \n",
    "        \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>a_k_prefered_a_j</th>\n",
       "      <th>preference_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[0.016954008231123023, 0.2797415948035028]</td>\n",
       "      <td>[0.3778461622191856, -0.12215383778081441]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[0.02254884012719308, -0.007546228302617475]</td>\n",
       "      <td>[0.8778461622191855, 0.3778461622191856]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[0.016537309513343704, -0.5785659270631498]</td>\n",
       "      <td>[-0.12215383778081441, 0.8778461622191855]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[0.016537309513343704, -0.5785659270631498]</td>\n",
       "      <td>[0.3778461622191856, 0.8778461622191855]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[0.004965990972080708, -0.8659936962966013]</td>\n",
       "      <td>[-0.12215383778081441, 0.3778461622191856]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1664</td>\n",
       "      <td>[0.03710083970251276, 0.023911501320636575]</td>\n",
       "      <td>[0.8778461622191855, -0.12215383778081441]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1665</td>\n",
       "      <td>[0.03710083970251276, 0.023911501320636575]</td>\n",
       "      <td>[0.8778461622191855, 0.3778461622191856]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1666</td>\n",
       "      <td>[0.03757906972892549, -0.2568386990573605]</td>\n",
       "      <td>[-0.12215383778081441, 0.3778461622191856]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1667</td>\n",
       "      <td>[0.03244229574777828, 0.04745640245454513]</td>\n",
       "      <td>[0.8778461622191855, 0.3778461622191856]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1668</td>\n",
       "      <td>[0.028695088905203538, 0.06820906688535988]</td>\n",
       "      <td>[0.8778461622191855, 0.3778461622191856]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1669 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             state  \\\n",
       "0       [0.016954008231123023, 0.2797415948035028]   \n",
       "1     [0.02254884012719308, -0.007546228302617475]   \n",
       "2      [0.016537309513343704, -0.5785659270631498]   \n",
       "3      [0.016537309513343704, -0.5785659270631498]   \n",
       "4      [0.004965990972080708, -0.8659936962966013]   \n",
       "...                                            ...   \n",
       "1664   [0.03710083970251276, 0.023911501320636575]   \n",
       "1665   [0.03710083970251276, 0.023911501320636575]   \n",
       "1666    [0.03757906972892549, -0.2568386990573605]   \n",
       "1667    [0.03244229574777828, 0.04745640245454513]   \n",
       "1668   [0.028695088905203538, 0.06820906688535988]   \n",
       "\n",
       "                                a_k_prefered_a_j  preference_label  \n",
       "0     [0.3778461622191856, -0.12215383778081441]                 1  \n",
       "1       [0.8778461622191855, 0.3778461622191856]                 1  \n",
       "2     [-0.12215383778081441, 0.8778461622191855]                 1  \n",
       "3       [0.3778461622191856, 0.8778461622191855]                 1  \n",
       "4     [-0.12215383778081441, 0.3778461622191856]                 1  \n",
       "...                                          ...               ...  \n",
       "1664  [0.8778461622191855, -0.12215383778081441]                 1  \n",
       "1665    [0.8778461622191855, 0.3778461622191856]                 1  \n",
       "1666  [-0.12215383778081441, 0.3778461622191856]                 1  \n",
       "1667    [0.8778461622191855, 0.3778461622191856]                 1  \n",
       "1668    [0.8778461622191855, 0.3778461622191856]                 1  \n",
       "\n",
       "[1669 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Label Ranker ###\n",
    "\n",
    "# To-be completed after creating a training-dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.00736531, 0.26078459])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_posi, c_velo = 0,0 # manually define state-values for 'cart-position' & 'cart-velocity'\n",
    "np.concatenate((np.array([c_posi,c_velo]),sample_states[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v0')\n",
    "c_posi, c_velo = 0,0 # manually define state-values for 'cart-position' & 'cart-velocity'\n",
    "env = env.unwrapped\n",
    "env = wrappers.Monitor(env, \"./gym-results\", force=True)\n",
    "env.reset()\n",
    "env.state = np.concatenate((np.array([c_posi,c_velo]),sample_states[0]))\n",
    "for _ in range(100):\n",
    "    action = env.action_space.sample()\n",
    "    observation, reward, done, info = env.step(action)\n",
    "    if done: break\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <video width=\"360\" height=\"auto\" alt=\"test\" controls><source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" /></video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video = io.open('./gym-results/openaigym.video.%s.video000000.mp4' % env.file_infix, 'r+b').read()\n",
    "encoded = base64.b64encode(video)\n",
    "HTML(data='''\n",
    "    <video width=\"360\" height=\"auto\" alt=\"test\" controls><source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" /></video>'''\n",
    ".format(encoded.decode('ascii')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APPENDIX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <video width=\"360\" height=\"auto\" alt=\"test\" controls><source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" /></video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make('CartPole-v0')\n",
    "env = wrappers.Monitor(env, \"./gym-results\", force=True)\n",
    "env.reset()\n",
    "for _ in range(1000):\n",
    "    action = env.action_space.sample()\n",
    "    observation, reward, done, info = env.step(action)\n",
    "    if done: break\n",
    "env.close()\n",
    "\n",
    "video = io.open('./gym-results/openaigym.video.%s.video000000.mp4' % env.file_infix, 'r+b').read()\n",
    "encoded = base64.b64encode(video)\n",
    "HTML(data='''\n",
    "    <video width=\"360\" height=\"auto\" alt=\"test\" controls><source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" /></video>'''\n",
    ".format(encoded.decode('ascii')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 19 finished after 8 timesteps. Total reward: 8.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nb_episodes = 20\n",
    "nb_timesteps = 100\n",
    "img = plt.imshow(env.render(mode='rgb_array')) # only call this once\n",
    "\n",
    "for episode in range(nb_episodes):  # iterate over the episodes\n",
    "    state = env.reset()             # initialise the environment\n",
    "    rewards = []\n",
    "    \n",
    "    for t in range(nb_timesteps):    # iterate over time steps\n",
    "        #env.render()                 # display the environment\n",
    "        img.set_data(env.render(mode='rgb_array')) # just update the data\n",
    "        display.display(plt.gcf())\n",
    "        display.clear_output(wait=True)\n",
    "        state, reward, done, info = env.step(0)  # implement the action chosen by the policy\n",
    "        rewards.append(reward)      # add 1 to the rewards list\n",
    "        \n",
    "        if done: # the episode ends either if the pole is > 15 deg from vertical or the cart move by > 2.4 unit from the centre\n",
    "            cumulative_reward = sum(rewards)\n",
    "            print(\"episode {} finished after {} timesteps. Total reward: {}\".format(episode, t+1, cumulative_reward))  \n",
    "            break\n",
    "    \n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
